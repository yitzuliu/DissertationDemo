# SmolVLM2 Testing Requirements
torch>=2.0.0
transformers>=4.40.0
pillow>=9.0.0
accelerate>=0.20.0

# Optional but recommended for better performance
flash-attn>=2.0.0  # For CUDA devices only

# For MLX inference on Mac (optional)
# mlx-vlm

# For video inference (optional)
# opencv-python
# numpy 