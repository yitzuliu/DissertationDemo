#!/usr/bin/env python3
"""
SmolVLM2 Multiple Image Inference (Legacy - Deprecated)
This file has been reorganized. Use the new MLX-optimized multi-image processing:
- inference/multi_image.py for multi-image comparison
"""

# DEPRECATED: This approach uses transformers/torch
# NEW: Use MLX-optimized multi-image processing for Apple Silicon

# Legacy approach (for reference only)
# messages = [
#     {
#         "role": "user",
#         "content": [
#             {"type": "text", "text": "What are the differences between these two images?"},
#           {"type": "image", "url": "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bee.jpg"},
#           {"type": "image", "url": "https://huggingface.co/datasets/huggingface/documentation-images/resolve/0052a70beed5bf71b92610a43a52df6d286cd5f3/diffusers/rabbit.jpg"},            
#         ]
#     },
# ]
# 
# inputs = processor.apply_chat_template(
#     messages,
#     add_generation_prompt=True,
#     tokenize=True,
#     return_dict=True,
#     return_tensors="pt",
# ).to(model.device, dtype=torch.bfloat16)
# 
# generated_ids = model.generate(**inputs, do_sample=False, max_new_tokens=64)
# generated_texts = processor.batch_decode(
#     generated_ids,
#     skip_special_tokens=True,
# )
# 
# print(generated_texts[0])

# NEW MLX-optimized multi-image processing example
print("‚ö†Ô∏è  DEPRECATED: This file has been reorganized for Apple Silicon optimization")
print("üîÑ Use the new MLX-optimized multi-image processing:")
print()
print("Example usage:")
print("  python inference/multi_image.py image1.jpg image2.jpg \\")
print("    --prompt 'What are the differences between these images?'")
print()
print("Or programmatically:")
print("  from inference.multi_image import SmolVLM2MultiImageProcessor")
print("  processor = SmolVLM2MultiImageProcessor()")
print("  result = processor.compare_images([")
print("    'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bee.jpg',")
print("    'https://huggingface.co/datasets/huggingface/documentation-images/resolve/0052a70beed5bf71b92610a43a52df6d286cd5f3/diffusers/rabbit.jpg'")
print("  ], 'What are the differences between these images?')")
print("  print(result['response'])")
print()
print("üìö See README.md for complete multi-image processing examples")

# Example of new multi-image processing
def example_multi_image_processing():
    """Example of new MLX-optimized multi-image processing"""
    try:
        from inference.multi_image import SmolVLM2MultiImageProcessor
        
        processor = SmolVLM2MultiImageProcessor()
        
        # Example images from the original code
        images = [
            "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bee.jpg",
            "https://huggingface.co/datasets/huggingface/documentation-images/resolve/0052a70beed5bf71b92610a43a52df6d286cd5f3/diffusers/rabbit.jpg"
        ]
        
        result = processor.compare_images(
            images=images,
            prompt="What are the differences between these two images?",
            system_prompt="You are an expert at comparing images. Focus on identifying key differences, similarities, and notable features.",
            max_tokens=512,
            temperature=0.7
        )
        
        if result["success"]:
            print("‚úÖ Multi-image comparison completed:")
            print(result["response"])
        else:
            print(f"‚ùå Error: {result['error']}")
            
    except ImportError:
        print("‚ùå New multi-image processing not available. Please install requirements:")
        print("  pip install -r requirements.txt")

if __name__ == "__main__":
    example_multi_image_processing()
