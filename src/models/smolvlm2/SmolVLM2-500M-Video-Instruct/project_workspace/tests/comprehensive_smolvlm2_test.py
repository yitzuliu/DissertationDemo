#!/usr/bin/env python3
"""
Comprehensive SmolVLM2-500M-Video-Instruct Testing Suite

Combined testing script for SmolVLM2-500M-Video-Instruct model with optimized MPS acceleration.
Includes image, video, and multi-modal testing capabilities.

Environment: Apple Silicon with MPS acceleration
Model: SmolVLM2-500M-Video-Instruct (1.9GB, 500M parameters)
"""

import torch
from PIL import Image
from transformers import AutoProcessor, AutoModelForImageTextToText
import os
import cv2
import numpy as np
from pathlib import Path
import time
from typing import Optional, List

class SmolVLM2TestSuite:
    """Comprehensive testing suite for SmolVLM2-500M-Video-Instruct."""
    
    def __init__(self):
        """Initialize the test suite with MPS optimization."""
        self.device = "mps"  # Force MPS for optimal Apple Silicon performance
        self.model: Optional[AutoModelForImageTextToText] = None
        self.processor: Optional[AutoProcessor] = None
        
        # Get the directory where this script is located (now inside project_workspace)
        script_dir = os.path.dirname(os.path.abspath(__file__))
        self.model_path = os.path.join(script_dir, "../..")  # Model files are in SmolVLM2-500M-Video-Instruct directory
        self.video_path = os.path.join(script_dir, "../../../../../debug/viedo/Generated File June 24, 2025 - 5_04PM.mp4")
        self.image_paths = [
            os.path.join(script_dir, "../../../../../debug/images/IMG_0119.JPG"),
            os.path.join(script_dir, "../../../../../debug/images/test_image.png"),
            os.path.join(script_dir, "../../../../../debug/images/sample.jpg"),
            os.path.join(script_dir, "../../../../../debug/images/test.jpg")
        ]
        
    def __del__(self):
        """Destructor to ensure memory cleanup when instance is deleted."""
        try:
            if hasattr(self, 'model') and self.model is not None:
                del self.model
            if hasattr(self, 'processor') and self.processor is not None:
                del self.processor
            self.cleanup_memory()
            print("ğŸ§¹ SmolVLM2TestSuite memory cleaned up")
        except Exception as e:
            print(f"âš ï¸ Cleanup warning in destructor: {e}")
        
    def load_model(self):
        """Load SmolVLM2 model with MPS optimization."""
        print("ğŸ SmolVLM2-500M Test Suite - MPS Accelerated")
        print("=" * 60)
        print("ğŸ”§ Hardware: Apple Silicon with MPS acceleration")
        print("ğŸ“Š Model: SmolVLM2-500M-Video-Instruct (500M params, 1.9GB)")
        print()
        
        start_time = time.time()
        print("ğŸ”„ Loading SmolVLM2-500M-Video-Instruct model...")
        
        try:
            # Load processor
            processor_start = time.time()
            self.processor = AutoProcessor.from_pretrained(self.model_path)
            processor_time = time.time() - processor_start
            
            # Load model with MPS-optimized settings
            model_start = time.time()
            self.model = AutoModelForImageTextToText.from_pretrained(
                self.model_path,
                torch_dtype=torch.float32,  # MPS-optimized precision
                device_map=None,  # Manual device management for MPS
            )
            self.model = self.model.to(self.device)
            model_time = time.time() - model_start
            
            total_time = time.time() - start_time
            
            print(f"âœ… Processor loaded: {processor_time:.2f}s")
            print(f"âœ… Model loaded: {model_time:.2f}s")
            print(f"âœ… Total loading time: {total_time:.2f}s")
            print(f"ğŸš€ Device: {self.device} (MPS acceleration active)")
            print()
            
        except Exception as e:
            print(f"âŒ Error loading model: {e}")
            return False
        
        return True
    
    def extract_video_frames(self, video_path, max_frames=3, target_fps=1, max_size=384):
        """Extract frames from video for SmolVLM2 processing with aggressive size optimization."""
        print(f"ğŸ“¹ Extracting frames from video...")
        
        if not os.path.exists(video_path):
            print(f"âŒ Video file not found: {video_path}")
            return []
        
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print(f"âŒ Could not open video file: {video_path}")
            return []
        
        # Get video properties
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = total_frames / fps
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        print(f"ğŸ“Š Video: {total_frames} frames, {fps:.1f} FPS, {duration:.1f}s, {width}x{height}")
        
        # Calculate frame sampling interval
        frame_interval = max(1, int(fps / target_fps))
        
        frames = []
        frame_count = 0
        
        while len(frames) < max_frames:
            ret, frame = cap.read()
            if not ret:
                break
            
            if frame_count % frame_interval == 0:
                # Convert BGR to RGB
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                
                # Aggressively resize frame to reduce memory usage
                if max(frame_rgb.shape[:2]) > max_size:
                    scale = max_size / max(frame_rgb.shape[:2])
                    new_height = int(frame_rgb.shape[0] * scale)
                    new_width = int(frame_rgb.shape[1] * scale)
                    frame_rgb = cv2.resize(frame_rgb, (new_width, new_height), interpolation=cv2.INTER_AREA)
                    print(f"ğŸ”„ Resized frame from {width}x{height} to {new_width}x{new_height}")
                
                # Convert to PIL Image
                pil_image = Image.fromarray(frame_rgb)
                frames.append(pil_image)
            
            frame_count += 1
        
        cap.release()
        print(f"âœ… Extracted {len(frames)} frames (max {max_size}px) for processing")
        return frames
    
    def cleanup_memory(self, aggressive=False):
        """Explicit memory cleanup method with optional aggressive mode."""
        try:
            if aggressive:
                # More aggressive cleanup
                import gc
                gc.collect()  # Force Python garbage collection
                print("ğŸ—‘ï¸ Python garbage collected")
            
            torch.mps.empty_cache()
            
            # Check memory after cleanup
            try:
                memory_used = torch.mps.current_allocated_memory() / 1024**3
                print(f"ğŸ§¹ MPS cache cleared (Current: {memory_used:.2f} GB)")
            except:
                print("ğŸ§¹ MPS cache cleared")
                
        except Exception as e:
            print(f"âš ï¸ Memory cleanup warning: {e}")
    
    def check_memory_availability(self, required_gb=2.0):
        """Check if enough memory is available for operation."""
        try:
            current_memory = torch.mps.current_allocated_memory() / 1024**3
            max_memory = 18.13  # Based on the error message
            available = max_memory - current_memory
            
            if available < required_gb:
                print(f"âš ï¸ Low memory: {available:.2f} GB available, {required_gb:.2f} GB required")
                self.cleanup_memory(aggressive=True)
                return False
            else:
                print(f"âœ… Memory OK: {available:.2f} GB available")
                return True
                
        except Exception as e:
            print(f"âš ï¸ Memory check failed: {e}")
            return True  # Assume OK if can't check
    
    def generate_response(self, messages, max_tokens=150):
        """çµ±ä¸€çš„æ¨ç†å‡½æ•¸ï¼Œæ”¹å–„è¨˜æ†¶é«”ç®¡ç†"""
        # Pre-check memory availability
        if not self.check_memory_availability(required_gb=3.0):
            raise RuntimeError("Insufficient memory for inference")
        
        start_time = time.time()
        
        inputs = self.processor.apply_chat_template(
            messages,
            add_generation_prompt=True,
            tokenize=True,
            return_dict=True,
            return_tensors="pt",
        )
        
        # MPS-optimized tensor handling
        inputs = {k: v.to(self.device, dtype=torch.float32 if v.dtype.is_floating_point else v.dtype) 
                 for k, v in inputs.items()}
        
        with torch.no_grad():
            generated_ids = self.model.generate(
                **inputs,
                max_new_tokens=max_tokens,
                do_sample=True,
                temperature=0.7,
                pad_token_id=self.processor.tokenizer.eos_token_id
            )
        
        generated_texts = self.processor.batch_decode(generated_ids, skip_special_tokens=True)
        inference_time = time.time() - start_time
        
        # å¼·åŒ–è¨˜æ†¶é«”æ¸…ç†
        del inputs, generated_ids
        self.cleanup_memory(aggressive=True)
        
        # Extract response
        full_response = generated_texts[0]
        if "Assistant:" in full_response:
            response = full_response.split("Assistant:")[-1].strip()
        else:
            response = full_response
        
        return response, inference_time
    
    def test_image_analysis(self):
        """Test SmolVLM2 with image analysis."""
        print("ğŸ–¼ï¸ IMAGE ANALYSIS TESTING")
        print("-" * 40)
        
        # Find available test images
        available_images = []
        for img_path in self.image_paths:
            if os.path.exists(img_path):
                available_images.append(img_path)
        
        if not available_images:
            print("âŒ No test images found")
            return
        
        test_prompts = [
            "Describe what you see in this image in detail.",
            "What objects are visible in this image?",
            "What colors and textures can you identify?",
            "Is there any text visible in this image?",
            "What is the overall scene or setting?"
        ]
        
        for i, img_path in enumerate(available_images[:2], 1):  # Test first 2 images
            print(f"\nğŸ“¸ Image Test {i}: {os.path.basename(img_path)}")
            
            try:
                # Load and resize image to prevent memory issues
                image = Image.open(img_path)
                original_size = image.size
                file_size = os.path.getsize(img_path) / 1024  # KB
                
                # Resize if too large
                max_size = 512
                if max(image.size) > max_size:
                    scale = max_size / max(image.size)
                    new_size = (int(image.size[0] * scale), int(image.size[1] * scale))
                    image = image.resize(new_size, Image.Resampling.LANCZOS)
                    print(f"ğŸ”„ Resized image from {original_size} to {image.size}")
                
                print(f"ğŸ“Š Size: {image.size}, {file_size:.1f}KB")
                
                # Test with a representative prompt
                prompt = test_prompts[0]  # Use first prompt for images
                
                messages = [
                    {
                        "role": "user",
                        "content": [
                            {"type": "image", "image": image},
                            {"type": "text", "text": prompt}
                        ]
                    }
                ]
                
                # Process and generate
                response, inference_time = self.generate_response(messages)
                
                print(f"âš¡ Inference time: {inference_time:.2f}s")
                print(f"ğŸ¤– Response: {response}")
                
                # æ˜ç¢ºæ¸…ç†æ¯å€‹åœ–åƒæ¸¬è©¦çš„è¨˜æ†¶é«”
                del image, messages
                self.cleanup_memory()
                
            except Exception as e:
                print(f"âŒ Error processing image {i}: {e}")
                # ç¢ºä¿å³ä½¿å‡ºéŒ¯ä¹Ÿæ¸…ç†è¨˜æ†¶é«”
                try:
                    self.cleanup_memory()
                except:
                    pass
    
    def test_single_frame_video(self):
        """Test SmolVLM2 with single frame from video."""
        print("ğŸ¬ SINGLE FRAME VIDEO TESTING")
        print("-" * 40)
        
        if not os.path.exists(self.video_path):
            print(f"âŒ Video file not found: {self.video_path}")
            return
        
        try:
            # Extract first frame
            cap = cv2.VideoCapture(self.video_path)
            ret, frame = cap.read()
            cap.release()
            
            if not ret:
                print("âŒ Could not read frame from video")
                return
            
            # Convert to PIL Image with size optimization
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            # Resize frame if too large to prevent memory issues
            max_size = 512
            if max(frame_rgb.shape[:2]) > max_size:
                scale = max_size / max(frame_rgb.shape[:2])
                new_height = int(frame_rgb.shape[0] * scale)
                new_width = int(frame_rgb.shape[1] * scale)
                frame_rgb = cv2.resize(frame_rgb, (new_width, new_height), interpolation=cv2.INTER_AREA)
                print(f"ğŸ”„ Resized frame to {new_width}x{new_height}")
            
            image = Image.fromarray(frame_rgb)
            print(f"ğŸ“¸ Extracted single frame: {image.size}")
            
            prompt = "Describe what you see in this frame from the video."
            
            messages = [
                {
                    "role": "user",
                    "content": [
                        {"type": "image", "image": image},
                        {"type": "text", "text": prompt}
                    ]
                }
            ]
            
            # Process and generate
            response, inference_time = self.generate_response(messages)
            
            print(f"âš¡ Inference time: {inference_time:.2f}s")
            print(f"ğŸ¤– Response: {response}")
            
            # æ˜ç¢ºæ¸…ç†å¹€æ•¸æ“š
            del frame, frame_rgb, image, messages
            self.cleanup_memory()
            
        except Exception as e:
            print(f"âŒ Error in single frame test: {e}")
            # ç¢ºä¿å³ä½¿å‡ºéŒ¯ä¹Ÿæ¸…ç†è¨˜æ†¶é«”
            try:
                self.cleanup_memory()
            except:
                pass
    
    def test_multi_frame_video(self):
        """Test SmolVLM2 with multiple frames as images with adaptive memory management."""
        print("ğŸ¥ MULTI-FRAME VIDEO TESTING (Frame Extraction)")
        print("-" * 40)
        
        test_prompts = [
            "Describe what happens across these video frames.",
            "What objects do you see in these frames?",
            "What is the main activity taking place?",
            "Describe any changes or movements you notice."
        ]
        
        # åªæ¸¬è©¦ç¬¬ä¸€å€‹æç¤ºè©ï¼Œæ¸›å°‘è¨˜æ†¶é«”è² è¼‰
        for i, prompt in enumerate(test_prompts[:1], 1):  # å¾[:2]æ”¹ç‚º[:1]
            print(f"\nğŸ” Multi-frame Test {i}: {prompt}")
            
            # å˜—è©¦ä¸åŒçš„å¹€æ•¸é…ç½®ï¼Œå¾å°‘åˆ°å¤š
            frame_configs = [
                (2, 320),  # 2å¹€ï¼Œ320px - æœ€ä¿å®ˆ
                (3, 384),  # 3å¹€ï¼Œ384px - ä¸­ç­‰
            ]
            
            success = False
            for max_frames, max_size in frame_configs:
                print(f"ğŸ”„ Trying {max_frames} frames at {max_size}px...")
                
                try:
                    # ç‚ºæ¯å€‹æ¸¬è©¦é‡æ–°æå–å¹€ï¼Œé¿å…ç´¯ç©
                    frames = self.extract_video_frames(self.video_path, max_frames=max_frames, target_fps=1, max_size=max_size)
                    
                    if not frames:
                        print("âŒ No frames extracted from video")
                        continue
                    
                    # Create message with multiple image tokens
                    content = [{"type": "text", "text": prompt}]
                    for frame in frames:
                        content.append({"type": "image", "image": frame})
                    
                    messages = [
                        {
                            "role": "user",
                            "content": content
                        }
                    ]
                    
                    # Process and generate
                    response, inference_time = self.generate_response(messages, max_tokens=200)
                    
                    print(f"âš¡ Inference time: {inference_time:.2f}s")
                    print(f"ğŸ¤– Response: {response}")
                    
                    # æ˜ç¢ºæ¸…ç†æœ¬æ¬¡æ¸¬è©¦çš„å¹€
                    del frames, content, messages
                    self.cleanup_memory()
                    
                    success = True
                    break  # æˆåŠŸå‰‡è·³å‡ºå¾ªç’°
                    
                except Exception as e:
                    if "out of memory" in str(e).lower():
                        print(f"ğŸ’¾ Memory insufficient for {max_frames} frames at {max_size}px, trying smaller...")
                        # ç¢ºä¿å³ä½¿å‡ºéŒ¯ä¹Ÿæ¸…ç†è¨˜æ†¶é«”
                        try:
                            del frames
                            self.cleanup_memory()
                        except:
                            pass
                        continue  # å˜—è©¦ä¸‹ä¸€å€‹é…ç½®
                    else:
                        print(f"âŒ Error in multi-frame test {i}: {e}")
                        try:
                            del frames
                            self.cleanup_memory()
                        except:
                            pass
                        break  # éè¨˜æ†¶é«”éŒ¯èª¤ï¼Œåœæ­¢å˜—è©¦
            
            if not success:
                print("âŒ Multi-frame test failed with all configurations")
    
    def test_direct_video(self):
        """Test SmolVLM2 with direct video path (README format)."""
        print("ğŸ“¹ DIRECT VIDEO TESTING (README Format)")
        print("-" * 40)
        
        if not os.path.exists(self.video_path):
            print(f"âŒ Video file not found: {self.video_path}")
            return
        
        video_abs_path = os.path.abspath(self.video_path)
        video_size = os.path.getsize(video_abs_path) / 1024 / 1024  # MB
        print(f"ğŸ“¹ Video: {video_size:.1f}MB - {os.path.basename(video_abs_path)}")
        
        test_prompts = [
            "Describe this video in detail",
            "What is happening in this video?",
            "What objects do you see in this video?"
        ]
        
        # åªæ¸¬è©¦ç¬¬ä¸€å€‹æç¤ºè©ï¼Œæ¸›å°‘è¨˜æ†¶é«”è² è¼‰
        for i, prompt in enumerate(test_prompts[:1], 1):  # å¾[:2]æ”¹ç‚º[:1]
            print(f"\nğŸ” Direct Video Test {i}: {prompt}")
            
            try:
                # Using exact README format
                messages = [
                    {
                        "role": "user",
                        "content": [
                            {"type": "video", "path": video_abs_path},
                            {"type": "text", "text": prompt}
                        ]
                    }
                ]
                
                # Process and generate
                response, inference_time = self.generate_response(messages, max_tokens=200)
                
                print(f"âš¡ Inference time: {inference_time:.2f}s")
                print(f"ğŸ¤– Response: {response}")
                
                # æ˜ç¢ºæ¸…ç†è¨Šæ¯æ•¸æ“š
                del messages
                self.cleanup_memory()
                
            except Exception as e:
                print(f"âŒ Error in direct video test {i}: {e}")
                if "pyav" in str(e).lower() or "av" in str(e).lower():
                    print("ğŸ’¡ Hint: Make sure PyAV is installed: pip install av")
                # ç¢ºä¿å³ä½¿å‡ºéŒ¯ä¹Ÿæ¸…ç†è¨˜æ†¶é«”
                try:
                    self.cleanup_memory()
                except:
                    pass
    
    def show_memory_usage(self):
        """Display current MPS memory usage."""
        try:
            memory_used = torch.mps.current_allocated_memory() / 1024**3
            print(f"\nğŸ“Š MPS Memory Usage: {memory_used:.2f} GB")
        except:
            print("\nğŸ“Š Memory monitoring not available")
    
    def run_comprehensive_test(self):
        """Run all test categories with enhanced memory management."""
        if not self.load_model():
            return
        
        print("ğŸ§ª COMPREHENSIVE SMOLVLM2 TESTING SUITE")
        print("=" * 60)
        
        # Test 1: Image Analysis
        try:
            self.test_image_analysis()
            self.show_memory_usage()
            # æ¸¬è©¦ä¹‹é–“å¼·åˆ¶æ¸…ç†è¨˜æ†¶é«”
            self.cleanup_memory()
        except Exception as e:
            print(f"âŒ Image testing failed: {e}")
            self.cleanup_memory()
        
        print("\n" + "="*60)
        
        # Test 2: Single Frame Video
        try:
            self.test_single_frame_video()
            self.show_memory_usage()
            # æ¸¬è©¦ä¹‹é–“å¼·åˆ¶æ¸…ç†è¨˜æ†¶é«”
            self.cleanup_memory()
        except Exception as e:
            print(f"âŒ Single frame testing failed: {e}")
            self.cleanup_memory()
        
        print("\n" + "="*60)
        
        # Test 3: Multi-Frame Video
        try:
            self.test_multi_frame_video()
            self.show_memory_usage()
            # æ¸¬è©¦ä¹‹é–“å¼·åˆ¶æ¸…ç†è¨˜æ†¶é«”
            self.cleanup_memory()
        except Exception as e:
            print(f"âŒ Multi-frame testing failed: {e}")
            self.cleanup_memory()
        
        print("\n" + "="*60)
        
        # Test 4: Direct Video (README format)
        try:
            self.test_direct_video()
            self.show_memory_usage()
            # æ¸¬è©¦ä¹‹é–“å¼·åˆ¶æ¸…ç†è¨˜æ†¶é«”
            self.cleanup_memory()
        except Exception as e:
            print(f"âŒ Direct video testing failed: {e}")
            self.cleanup_memory()
        
        print("\n" + "="*60)
        print("âœ… COMPREHENSIVE TESTING COMPLETE")
        self.show_memory_usage()
        # æœ€çµ‚æ¸…ç†
        self.cleanup_memory()
    
    def run_quick_test(self):
        """Run a quick test with one example from each category."""
        if not self.load_model():
            return
        
        print("âš¡ QUICK SMOLVLM2 TEST")
        print("=" * 40)
        
        # Quick image test
        try:
            print("ğŸ“¸ Quick Image Test...")
            self.test_image_analysis()
        except Exception as e:
            print(f"âŒ Quick image test failed: {e}")
        
        print("\n" + "-"*40)
        
        # Quick video test (direct method)
        try:
            print("ğŸ¬ Quick Video Test...")
            self.test_direct_video()
        except Exception as e:
            print(f"âŒ Quick video test failed: {e}")
        
        print("\n" + "="*40)
        print("âœ… QUICK TEST COMPLETE")
        self.show_memory_usage()


def main():
    """Main testing interface with improved memory management."""
    test_suite = SmolVLM2TestSuite()
    
    try:
        print("ğŸ¬ SmolVLM2-500M-Video-Instruct Testing Suite")
        print("=" * 50)
        print("ğŸ Optimized for Apple Silicon with MPS acceleration")
        print()
        print("Testing Options:")
        print("1. Comprehensive Test (all categories)")
        print("2. Quick Test (representative samples)")
        print("3. Image Analysis Only")
        print("4. Video Testing Only (all methods)")
        print("5. Direct Video Test (README format)")
        print("6. Frame Extraction Preview")
        
        choice = input("\nEnter your choice (1-6): ").strip()
        
        if choice == "1":
            test_suite.run_comprehensive_test()
        elif choice == "2":
            test_suite.run_quick_test()
        elif choice == "3":
            if test_suite.load_model():
                test_suite.test_image_analysis()
                test_suite.show_memory_usage()
        elif choice == "4":
            if test_suite.load_model():
                test_suite.test_single_frame_video()
                print("\n" + "-"*40)
                test_suite.test_multi_frame_video()
                print("\n" + "-"*40)
                test_suite.test_direct_video()
                test_suite.show_memory_usage()
        elif choice == "5":
            if test_suite.load_model():
                test_suite.test_direct_video()
                test_suite.show_memory_usage()
        elif choice == "6":
            frames = test_suite.extract_video_frames(test_suite.video_path, max_frames=5)
            if frames:
                print(f"\nğŸ–¼ï¸ Frame Preview: {len(frames)} frames extracted")
                for i, frame in enumerate(frames):
                    print(f"Frame {i+1}: {frame.size} pixels")
                # æ¸…ç†é è¦½å¹€
                del frames
                test_suite.cleanup_memory()
        else:
            print("âŒ Invalid choice. Please run the script again.")
    
    finally:
        # ç¢ºä¿æ¸¬è©¦å¥—ä»¶è¢«æ­£ç¢ºæ¸…ç†
        try:
            del test_suite
            print("\nğŸ§¹ Test suite cleaned up successfully")
        except Exception as e:
            print(f"\nâš ï¸ Cleanup warning: {e}")


if __name__ == "__main__":
    main() 