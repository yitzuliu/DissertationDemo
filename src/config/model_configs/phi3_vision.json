{
  "model_name": "Phi-3.5-Vision",
  "model_id": "phi3_vision",
  "model_path": "mlx-community/Phi-3.5-vision-instruct-4bit",
  "device": "auto",
  "timeout": 180,
  "max_tokens": 100,
  "version": "standard",
  "description": "Standard Phi-3.5-Vision model using MLX-VLM for Apple Silicon optimization",
  
  "capabilities": {
    "vision": true,
    "text_generation": true,
    "image_understanding": true,
    "conversation": true,
    "multimodal": true,
    "apple_silicon_optimized": true
  },
  
  "model_config": {
    "torch_dtype": "float16",
    "device_map": "auto",
    "trust_remote_code": true,
    "low_cpu_mem_usage": true,
    "_attn_implementation": "eager"
  },
  
  "mlx_config": {
    "use_mlx": true,
    "model_id": "mlx-community/Phi-3.5-vision-instruct-4bit",
    "quantization_bits": 4,
    "fallback_to_transformers": true,
    "temp_image_cleanup": true
  },
  
  "image_processing": {
    "size": [512, 512],
    "max_size": 1024,
    "format": "RGB",
    "quality": 95,
    "preserve_aspect_ratio": true
  },
  
  "generation_config": {
    "max_new_tokens": 100,
    "do_sample": false,
    "temperature": 0.7,
    "top_p": 0.9,
    "repetition_penalty": 1.1,
    "use_cache": false,
    "pad_token_id": "eos_token_id"
  },
  
  "server": {
    "host": "0.0.0.0",
    "port": 8080,
    "framework": "fastapi",
    "cors_enabled": true,
    "log_level": "info"
  },
  
  "performance": {
    "compile_model": false,
    "use_flash_attention": false,
    "enable_optimizations": true,
    "memory_optimization": "medium",
    "apple_silicon_mps": true
  },
  
  "special_tokens": {
    "image_token": "<|image_1|>",
    "user_prefix": "User:",
    "assistant_prefix": "Assistant:"
  },
  
  "limits": {
    "max_sequence_length": 2048,
    "max_image_size": 1024,
    "timeout_seconds": 180
  },
  
  "environment": {
    "required_packages": [
      "mlx-vlm>=0.0.9",
      "transformers>=4.40.0",
      "torch>=2.0.0",
      "Pillow>=9.0.0",
      "fastapi>=0.100.0",
      "uvicorn>=0.22.0"
    ],
    "python_version": ">=3.9",
    "platform": "darwin",
    "recommended_hardware": "Apple Silicon (M1/M2/M3)"
  },
  
  "fallback_config": {
    "enabled": true,
    "fallback_model_path": "microsoft/Phi-3.5-vision-instruct",
    "fallback_device": "cpu",
    "fallback_dtype": "float32"
  },
  
  "ui": {
    "default_instruction": "You are an AI Manual Assistant with advanced visual understanding capabilities. Your role is to analyze images and provide detailed, structured guidance.\n\nFor each image analysis, provide a comprehensive response with these components:\n\n[OBSERVATION]: Detailed description of what you see in the image, focusing on key elements and their relationships\n[TASK_IDENTIFICATION]: Identify the specific task or procedure being performed (e.g., \"kitchen-sink-installation\", \"computer-assembly\")\n[STEP_ANALYSIS]: Determine the current step number and estimate total steps (e.g., \"Step 3 of 8\")\n[STATUS_ASSESSMENT]: Evaluate if the current step is \"pending\", \"active\", \"done\", or has \"error\"\n[TOOLS_AND_MATERIALS]: List all visible tools, materials, and components in the image\n[GUIDANCE]: Provide clear, step-by-step instructions for completing the current task\n[SAFETY_CONSIDERATIONS]: Important safety warnings and precautions\n[ALTERNATIVE_APPROACHES]: Suggestions if standard tools or materials are unavailable\n[NEXT_STEP_PREVIEW]: Brief overview of what comes after the current step\n\nThis structured format will integrate with our knowledge retrieval system and help maintain task progress awareness across multiple interactions.",
    "capture_intervals": [1000, 2000, 5000, 10000, 15000],
    "default_interval": 5000
  }
}