{
  "model_name": "Phi-3.5-Vision-Optimized",
  "model_id": "phi3_vision_optimized",
  "model_path": "mlx-community/Phi-3.5-vision-instruct-4bit",
  "device": "auto",
  "timeout": 60,
  "max_tokens": 100,
  "version": "optimized_mlx",
  "description": "Optimized Phi-3.5-Vision model with MLX framework and INT4 quantization for Apple Silicon",
  "capabilities": {
    "vision": true,
    "text_generation": true,
    "image_understanding": true,
    "conversation": true,
    "multimodal": true,
    "apple_silicon_optimized": true
  },
  "model_config": {
    "torch_dtype": "float16",
    "device_map": "auto",
    "trust_remote_code": true,
    "low_cpu_mem_usage": true,
    "_attn_implementation": "eager",
    "quantization": "int4"
  },
  "mlx_config": {
    "use_mlx": true,
    "model_id": "mlx-community/Phi-3.5-vision-instruct-4bit",
    "quantization_bits": 4,
    "fallback_to_transformers": true,
    "temp_image_cleanup": true
  },
  "image_processing": {
    "size": [
      384,
      384
    ],
    "max_size": 1024,
    "format": "RGB",
    "quality": 95,
    "preserve_aspect_ratio": true,
    "cache_enabled": true,
    "cache_size": 15
  },
  "generation_config": {
    "max_new_tokens": 100,
    "do_sample": false,
    "temperature": 0.7,
    "top_p": 0.9,
    "repetition_penalty": 1.2,
    "use_cache": false,
    "pad_token_id": "eos_token_id"
  },
  "server": {
    "host": "0.0.0.0",
    "port": 8080,
    "framework": "flask",
    "cors_enabled": true,
    "log_level": "info",
    "threaded": true,
    "processes": 1
  },
  "performance": {
    "compile_model": false,
    "use_flash_attention": false,
    "enable_optimizations": true,
    "memory_optimization": "high",
    "apple_silicon_mps": true,
    "int4_quantization": true,
    "image_caching": true,
    "smart_memory_cleanup": true
  },
  "optimization_flags": {
    "use_mps": true,
    "half_precision": true,
    "cache_image_preprocessing": true,
    "mlx_primary": true,
    "transformers_fallback": true,
    "memory_efficient": true
  },
  "special_tokens": {
    "image_token": "<|image_1|>",
    "user_prefix": "User:",
    "assistant_prefix": "Assistant:",
    "end_token": "<|end|>",
    "endoftext_token": "<|endoftext|>"
  },
  "limits": {
    "max_sequence_length": 2048,
    "max_image_size": 1024,
    "timeout_seconds": 60,
    "max_tokens_cap": 150
  },
  "cache_settings": {
    "image_cache_size": 15,
    "response_cache_size": 50,
    "temp_file_cleanup": true,
    "cleanup_interval": 5
  },
  "environment": {
    "required_packages": [
      "mlx-vlm>=0.0.9",
      "mlx>=0.11.0",
      "transformers>=4.40.0",
      "torch>=2.0.0",
      "Pillow>=9.0.0",
      "flask>=2.3.0"
    ],
    "optional_packages": [
      "mlx-lm",
      "accelerate"
    ],
    "python_version": ">=3.9",
    "platform": "darwin",
    "recommended_hardware": "Apple Silicon (M1/M2/M3)"
  },
  "fallback_config": {
    "enabled": true,
    "fallback_model_path": "microsoft/Phi-3.5-vision-instruct",
    "fallback_device": "cpu",
    "fallback_dtype": "float32"
  },
  "ui": {
    "default_instruction": "You are an phi3_vision_optimized Manual Assistant with advanced visual understanding and state tracking capabilities. Your role is to analyze images.And tell me what you see in the image. You can also answer questions about the image and provide detailed explanations.",
    "capture_intervals": [1000, 2000, 5000, 10000, 15000],
    "default_interval": 5000
  }
}