{
  "model_name": "LLaVA-MLX",
  "model_id": "llava_mlx",
  "model_path": "mlx-community/llava-v1.6-mistral-7b-4bit",
  "device": "auto",
  "timeout": 180,
  "max_tokens": 150,
  "version": "1.0.0",
  "description": "LLaVA MLX model optimized for Apple Silicon with INT4 quantization",
  
  "capabilities": {
    "vision": true,
    "text_generation": true,
    "image_understanding": true,
    "conversation": true,
    "multimodal": true,
    "apple_silicon_optimized": true
  },
  
  "model_config": {
    "framework": "MLX-VLM",
    "quantization": "int4",
    "device": "auto",
    "trust_remote_code": true
  },
  
  "image_processing": {
    "size": [1024, 1024],
    "max_size": 1024,
    "format": "RGB",
    "quality": 95,
    "preserve_aspect_ratio": true
  },
  
  "generation_config": {
    "max_new_tokens": 150,
    "temperature": 0.7,
    "top_p": 0.9,
    "repetition_penalty": 1.2,
    "do_sample": false
  },
  
  "server": {
    "host": "0.0.0.0",
    "port": 8080,
    "framework": "flask",
    "timeout": 180
  },
  
  "performance": {
    "mlx_acceleration": true,
    "apple_silicon": true,
    "int4_quantization": true,
    "unified_preprocessing": true,
    "auto_model_reload": true,
    "max_inferences_before_reload": 1,
    "state_management": "aggressive_cleanup"
  },
  
  "stability": {
    "axis_remapping_prevention": true,
    "model_state_tracking": true,
    "automatic_recovery": true,
    "cache_cleanup_mode": "aggressive"
  },
  
  "requirements": [
    "mlx-vlm>=0.0.9",
    "mlx>=0.11.0",
    "Pillow>=9.0.0",
    "Flask>=2.3.0"
  ],
  
  "notes": [
    "This model is optimized for Apple Silicon (M1/M2/M3) and requires the 'mlx-vlm' package.",
    "Known to have issues with synthetic, square images. Performs best with photographic images.",
    "Uses INT4 quantization for memory efficiency."
  ],
  
  "ui": {
    "default_instruction": "You are an AI Manual Assistant with state tracking and knowledge retrieval capabilities. Your role is to analyze images of hands-on tasks and provide structured guidance while maintaining awareness of task progress.\n\nFor each image analysis, structure your response as follows:\n\n[OBSERVATION]: {Brief description of what you observe in the image}\n[TASK_IDENTIFICATION]: {Specific task name and category, e.g., \"Replacing Kitchen Faucet (Plumbing)\"}\n[PROGRESS_ASSESSMENT]: {Current step number and estimated total steps, e.g., \"Step 2 of 8\"}\n[STEP_STATUS]: {One of: \"pending\", \"active\", \"done\", \"error\"}\n[DETECTED_ITEMS]: {List of tools, materials, and components visible in the image}\n[CURRENT_STEP_GUIDANCE]: {Detailed instructions for completing the current step}\n[SAFETY_WARNINGS]: {Any relevant safety precautions}\n[ALTERNATIVE_APPROACHES]: {Suggestions if standard tools are unavailable}\n\nThis structured format will integrate with our RAG system to retrieve relevant procedural knowledge and with our State-Tracking module to maintain awareness of task progress across multiple interactions.",
    "capture_intervals": [1000, 2000, 5000, 10000],
    "default_interval": 5000
  }
}