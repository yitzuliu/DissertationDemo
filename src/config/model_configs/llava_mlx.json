{
  "model_name": "LLaVA-MLX",
  "model_path": "mlx-community/llava-v1.6-mistral-7b-4bit",
  "device": "mps",
  "quantization": "int4",
  "max_tokens": 150,
  "version": "1.0.0",
  "description": "LLaVA MLX model optimized for Apple Silicon with INT4 quantization",
  
  "capabilities": {
    "vision": true,
    "text_generation": true,
    "image_understanding": true,
    "conversation": true,
    "multimodal": true,
    "apple_silicon_optimized": true
  },
  
  "model_config": {
    "framework": "MLX-VLM",
    "quantization": "int4",
    "device": "auto",
    "trust_remote_code": true
  },
  
  "image_processing": {
    "max_size": 1024,
    "min_size": 224,
    "format": "RGB",
    "quality": 95
  },
  
  "generation_config": {
    "max_new_tokens": 150,
    "temperature": 0.7,
    "top_p": 0.9,
    "repetition_penalty": 1.2,
    "do_sample": false
  },
  
  "server": {
    "framework": "flask",
    "cors_enabled": true
  },
  
  "performance": {
    "mlx_acceleration": true,
    "apple_silicon": true,
    "int4_quantization": true,
    "unified_preprocessing": true,
    "auto_model_reload": true,
    "max_inferences_before_reload": 1,
    "state_management": "aggressive_cleanup"
  },
  
  "stability": {
    "axis_remapping_prevention": true,
    "model_state_tracking": true,
    "automatic_recovery": true,
    "cache_cleanup_mode": "aggressive"
  },
  
  "requirements": [
    "mlx-vlm>=0.0.9",
    "mlx>=0.11.0",
    "Pillow>=9.0.0",
    "Flask>=2.3.0"
  ],
  
  "notes": [
    "This model is optimized for Apple Silicon (M1/M2/M3) and requires the 'mlx-vlm' package.",
    "Known to have issues with synthetic, square images. Performs best with photographic images.",
    "Uses INT4 quantization for memory efficiency."
  ],
  
  "ui": {
    "default_instruction": "Analyze this image in detail.",
    "capture_intervals": [2000, 5000, 10000],
    "default_interval": 5000
  }
}