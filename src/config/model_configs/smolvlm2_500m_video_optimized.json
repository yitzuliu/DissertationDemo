{
  "model_name": "SmolVLM2-500M-Video-Optimized",
  "model_id": "smolvlm2_500m_video_optimized",
  "model_path": "HuggingFaceTB/SmolVLM2-500M-Video-Instruct",
  "device": "mps",
  "timeout": 90,
  "max_tokens": 150,
  "version": "optimized",
  "description": "Optimized SmolVLM2 500M Video model with MPS acceleration and memory optimizations",
  
  "capabilities": {
    "vision": true,
    "text_generation": true,
    "image_understanding": true,
    "video_understanding": true,
    "conversation": true,
    "multimodal": true,
    "apple_silicon_optimized": true
  },
  
  "model_config": {
    "torch_dtype": "float16",
    "device_map": "mps",
    "trust_remote_code": true,
    "low_cpu_mem_usage": true,
    "use_cache": true
  },
  
  "image_processing": {
    "size": [384, 384],
    "max_size": 512,
    "format": "RGB",
    "quality": 85,
    "preserve_aspect_ratio": true,
    "smart_crop": true,
    "cache_enabled": true
  },
  
  "generation_config": {
    "max_new_tokens": 150,
    "temperature": 0.7,
    "top_p": 0.9,
    "do_sample": false,
    "repetition_penalty": 1.1,
    "use_cache": true
  },
  
  "server": {
    "host": "0.0.0.0",
    "port": 8080,
    "framework": "flask",
    "threaded": true
  },
  
  "performance": {
    "mps_acceleration": true,
    "memory_optimization": true,
    "image_caching": true,
    "response_caching": true
  },
  
  "ui": {
    "default_instruction": "You are an AI Manual Assistant with optimized video understanding. Quickly analyze images in video context and provide structured guidance.\n\n[OBSERVATION]: Brief description of current frame\n[VIDEO_CONTEXT]: Relationship to video sequence\n[TASK]: Specific task identification\n[STEP]: Current step number and status\n[GUIDANCE]: Clear, numbered instructions\n[SAFETY]: Key safety points\n\nOptimized for fast, accurate responses with Apple Silicon acceleration.",
    "capture_intervals": [3000, 5000, 10000, 15000],
    "default_interval": 3000
  }
}