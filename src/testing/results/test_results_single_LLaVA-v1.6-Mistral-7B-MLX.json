{
  "test_timestamp": "2025-07-13 20:28:37",
  "system_info": {
    "device": "MacBook Air M3",
    "memory": "16GB",
    "mps_available": true
  },
  "models": {
    "LLaVA-v1.6-Mistral-7B-MLX": {
      "model_id": "mlx-community/llava-v1.6-mistral-7b-4bit",
      "load_time": 2.6468679904937744,
      "memory_before": 0.3440704345703125,
      "memory_after": 0.31488037109375,
      "memory_diff": -0.0291900634765625,
      "images": {
        "IMG_0119.JPG": {
          "inference_time": 8.315176963806152,
          "response": "\n\nThe image is a photograph of a person standing outdoors. The individual appears to be wearing a dark-colored top and light-colored pants. They are facing away from the camera, looking towards the right side of the frame. The person has short hair and is wearing glasses. The background is blurred but suggests a natural outdoor setting with greenery. There are no visible texts or distinguishing marks that provide additional context or information about the person or the location. The style of the",
          "image_info": {
            "original_size": [
              960,
              1707
            ],
            "processed_size": [
              575,
              1024
            ],
            "mode": "RGB",
            "file_size": 222091
          },
          "error": null,
          "unified_test": true,
          "generation_params": {
            "max_new_tokens": 100,
            "do_sample": false
          },
          "timeout_used": 180
        },
        "IMG_2053.JPG": {
          "inference_time": 8.056061029434204,
          "response": "\n\nThe image is a photograph of a person standing outdoors. The individual appears to be wearing a dark-colored top and light-colored pants. They are facing away from the camera, looking towards the right side of the frame. The person has short hair and is wearing glasses. The background is blurred but suggests a natural outdoor setting with greenery. There are no visible texts or distinguishing marks that provide additional context or information about the person or the location. The style of the",
          "image_info": {
            "original_size": [
              3088,
              2316
            ],
            "processed_size": [
              1024,
              768
            ],
            "mode": "RGB",
            "file_size": 1834456
          },
          "error": null,
          "unified_test": true,
          "generation_params": {
            "max_new_tokens": 100,
            "do_sample": false
          },
          "timeout_used": 180
        },
        "test_image.jpg": {
          "inference_time": 7.496531963348389,
          "response": "\n\nThe image is a photograph of a person standing outdoors. The individual appears to be wearing a dark-colored top and light-colored pants. They are facing away from the camera, looking towards the right side of the frame. The person has short hair and is wearing glasses. The background is blurred but suggests a natural outdoor setting with greenery. There are no visible texts or distinguishing marks that provide additional context or information about the person or the location. The style of the",
          "image_info": {
            "original_size": [
              336,
              336
            ],
            "processed_size": [
              336,
              336
            ],
            "mode": "RGB",
            "file_size": 11823
          },
          "error": null,
          "unified_test": true,
          "generation_params": {
            "max_new_tokens": 100,
            "do_sample": false
          },
          "timeout_used": 180
        }
      },
      "total_inference_time": 23.867769956588745,
      "successful_inferences": 3,
      "failed_inferences": 0,
      "avg_inference_time": 7.955923318862915,
      "memory_after_cleanup": 1.9061279296875
    }
  }
}