{
  "test_timestamp": "2025-07-12 08:47:39",
  "system_info": {
    "device": "MacBook Air M3",
    "memory": "16GB",
    "mps_available": true
  },
  "models": {
    "SmolVLM2-500M-Video-Instruct": {
      "model_id": "HuggingFaceTB/SmolVLM2-500M-Video-Instruct",
      "load_time": 2.579105854034424,
      "memory_before": 0.34454345703125,
      "memory_after": 0.4272613525390625,
      "memory_diff": 0.0827178955078125,
      "images": {
        "IMG_0119.JPG": {
          "inference_time": 11.384448051452637,
          "response": "User:\n\n\n\n\nDescribe what you see in this image in detail.\nAssistant: The image features a Shiba Inu dog, characterized by its tan and white fur, sitting on a tiled floor. The dog's face is prominently displayed, with its nose and mouth visible. The dog appears to be looking directly at the camera, giving a sense of curiosity or attentiveness. The background of the image includes a green shoe and a white wall, which are positioned relatively far from the camera.",
          "image_info": {
            "original_size": [
              960,
              1707
            ],
            "processed_size": [
              575,
              1024
            ],
            "mode": "RGB",
            "file_size": 222091
          },
          "error": null,
          "unified_test": true,
          "generation_params": {
            "max_new_tokens": 100,
            "do_sample": false
          },
          "timeout_used": 60
        },
        "test_image.jpg": {
          "inference_time": 13.407562017440796,
          "response": "User:\n\n\n\n\nDescribe what you see in this image in detail.\nAssistant: The image presents a geometric figure consisting of a red circle and a blue square. The circle is centrally located within the square, with the center of the circle marked by the letter \"P\" in blue. The blue square is positioned in the top right corner of the image, and it is bordered by a blue border. The background of the image is light blue, providing a neutral backdrop that allows the geometric shapes to stand out.\n\n### Description:\n- **Circle**: The red circle",
          "image_info": {
            "original_size": [
              336,
              336
            ],
            "processed_size": [
              336,
              336
            ],
            "mode": "RGB",
            "file_size": 11823
          },
          "error": null,
          "unified_test": true,
          "generation_params": {
            "max_new_tokens": 100,
            "do_sample": false
          },
          "timeout_used": 60
        },
        "test_image.png": {
          "inference_time": 12.323194980621338,
          "response": "User:\n\n\n\n\nDescribe what you see in this image in detail.\nAssistant: The image presents a geometric figure consisting of a red circle and a blue square. The circle is centrally located within the square, with the center of the circle marked by the letter \"P\" in blue. The blue square is positioned in the top right corner of the image, and it is bordered by a blue border.\n\nThe image does not contain any text or additional objects. The relative positions of the objects are as follows:\n- The red circle is centrally located within the blue square.",
          "image_info": {
            "original_size": [
              336,
              336
            ],
            "processed_size": [
              336,
              336
            ],
            "mode": "RGB",
            "file_size": 2305
          },
          "error": null,
          "unified_test": true,
          "generation_params": {
            "max_new_tokens": 100,
            "do_sample": false
          },
          "timeout_used": 60
        }
      },
      "total_inference_time": 37.11520504951477,
      "successful_inferences": 3,
      "failed_inferences": 0,
      "avg_inference_time": 12.371735016504923,
      "memory_after_cleanup": 2.9910888671875
    },
    "SmolVLM-500M-Instruct": {
      "model_id": "HuggingFaceTB/SmolVLM-500M-Instruct",
      "load_time": 3.5209550857543945,
      "memory_before": 1.2760772705078125,
      "memory_after": 1.754547119140625,
      "memory_diff": 0.4784698486328125,
      "images": {
        "IMG_0119.JPG": {
          "inference_time": 9.443297147750854,
          "response": "User:\n\n\n\n\nDescribe what you see in this image in detail.\nAssistant: A Shiba Inu dog with a black nose is sitting on a bathroom floor in front of a toilet and a hand sanitizer dispenser. The dog is looking directly at the camera. The dog has a light brown coat with a white patch of fur on its neck. The nose is black. The dog's left ear is black and its right ear is gray. The dog's mouth is closed. The floor is white with light gray tiles. There are two green slippers on the floor in front",
          "image_info": {
            "original_size": [
              960,
              1707
            ],
            "processed_size": [
              575,
              1024
            ],
            "mode": "RGB",
            "file_size": 222091
          },
          "error": null,
          "unified_test": true,
          "generation_params": {
            "max_new_tokens": 100,
            "do_sample": false
          },
          "timeout_used": 60
        },
        "test_image.jpg": {
          "inference_time": 11.556643962860107,
          "response": "User:\n\n\n\n\nDescribe what you see in this image in detail.\nAssistant: The image depicts a geometric figure consisting of a square and a circle. The square is light blue in color and has a blue border. The circle is red and is positioned inside the square. The circle is perfectly centered within the square.\n\n### Description:\n- **Square**: The square has four equal sides and four equal angles. The corners of the square are labeled with the numbers 1, 2, 3, and 4.\n- **Circle**: The circle",
          "image_info": {
            "original_size": [
              336,
              336
            ],
            "processed_size": [
              336,
              336
            ],
            "mode": "RGB",
            "file_size": 11823
          },
          "error": null,
          "unified_test": true,
          "generation_params": {
            "max_new_tokens": 100,
            "do_sample": false
          },
          "timeout_used": 60
        },
        "test_image.png": {
          "inference_time": 11.123554944992065,
          "response": "User:\n\n\n\n\nDescribe what you see in this image in detail.\nAssistant: The image depicts a geometric figure consisting of a red circle and a blue square. The circle is positioned in the center of the image, and it is filled with a solid red color. The blue square is placed directly above the red circle, and it is outlined in a darker blue color. The background of the image is a light blue color, which provides a neutral backdrop for the geometric shapes.\n\n### Analysis and Description:\n\n#### Geometry:\n1. **Circle**:\n   -",
          "image_info": {
            "original_size": [
              336,
              336
            ],
            "processed_size": [
              336,
              336
            ],
            "mode": "RGB",
            "file_size": 2305
          },
          "error": null,
          "unified_test": true,
          "generation_params": {
            "max_new_tokens": 100,
            "do_sample": false
          },
          "timeout_used": 60
        }
      },
      "total_inference_time": 32.12349605560303,
      "successful_inferences": 3,
      "failed_inferences": 0,
      "avg_inference_time": 10.707832018534342,
      "memory_after_cleanup": 3.125640869140625
    },
    "Moondream2": {
      "model_id": "vikhyatk/moondream2",
      "load_time": 4.912326097488403,
      "memory_before": 1.302581787109375,
      "memory_after": 0.0672454833984375,
      "memory_diff": -1.2353363037109375,
      "images": {
        "IMG_0119.JPG": {
          "inference_time": 8.051597118377686,
          "response": "In the center of the image, a light brown Shiba Inu dog is sitting comfortably on a tiled floor. The dog's attention is directed upwards, meeting the camera head-on. Its nose is black, and its eyes are wide open, giving the impression that it is curious or possibly surprised. \n\nTo the left of the dog, there is a green shoe placed on the floor. A small white electric fan is situated behind the dog, slightly to the left. The background features a wooden wall, adding a warm and homely touch to the scene.",
          "image_info": {
            "original_size": [
              960,
              1707
            ],
            "processed_size": [
              575,
              1024
            ],
            "mode": "RGB",
            "file_size": 222091
          },
          "error": null,
          "unified_test": true,
          "generation_params": {
            "max_new_tokens": 100,
            "do_sample": false
          },
          "timeout_used": 60
        },
        "test_image.jpg": {
          "inference_time": 3.6237339973449707,
          "response": "The image displays a simple diagram consisting of a blue square containing a red circle. The red circle is labeled \"PHI-3\" and is positioned in the center of the square. The entire diagram is set against a white background, creating a clear and easily readable visual representation.",
          "image_info": {
            "original_size": [
              336,
              336
            ],
            "processed_size": [
              336,
              336
            ],
            "mode": "RGB",
            "file_size": 11823
          },
          "error": null,
          "unified_test": true,
          "generation_params": {
            "max_new_tokens": 100,
            "do_sample": false
          },
          "timeout_used": 60
        },
        "test_image.png": {
          "inference_time": 4.564254999160767,
          "response": "The image displays a square-shaped diagram containing two distinct sections: a light blue square and a pink circle. Within the light blue square, the phrase \"PHI-3\" is inscribed in blue letters, indicating a possible association or grouping between these concepts. The pink circle, positioned within the light blue square, further emphasizes the connection or overlap between these two elements.",
          "image_info": {
            "original_size": [
              336,
              336
            ],
            "processed_size": [
              336,
              336
            ],
            "mode": "RGB",
            "file_size": 2305
          },
          "error": null,
          "unified_test": true,
          "generation_params": {
            "max_new_tokens": 100,
            "do_sample": false
          },
          "timeout_used": 60
        }
      },
      "total_inference_time": 16.239586114883423,
      "successful_inferences": 3,
      "failed_inferences": 0,
      "avg_inference_time": 5.413195371627808,
      "memory_after_cleanup": 0.4941253662109375
    },
    "LLaVA-v1.6-Mistral-7B-MLX": {
      "model_id": "mlx-community/llava-v1.6-mistral-7b-4bit",
      "load_time": 2.7583558559417725,
      "memory_before": 0.4983062744140625,
      "memory_after": 0.2947998046875,
      "memory_diff": -0.2035064697265625,
      "images": {
        "IMG_0119.JPG": {
          "inference_time": 5.856200933456421,
          "response": "\n\nThe image is a photograph of a person standing outdoors. The individual appears to be wearing a dark-colored top and light-colored pants. They are facing away from the camera, looking towards the right side of the frame. The person has short hair and is wearing glasses. The background is blurred but suggests a natural outdoor setting with greenery. There are no visible texts or distinguishing marks that provide additional context or information about the person or the location. The style of the",
          "image_info": {
            "original_size": [
              960,
              1707
            ],
            "processed_size": [
              575,
              1024
            ],
            "mode": "RGB",
            "file_size": 222091
          },
          "error": null,
          "unified_test": true,
          "generation_params": {
            "max_new_tokens": 100,
            "do_sample": false
          },
          "timeout_used": 180
        },
        "test_image.jpg": {
          "inference_time": 0.037039995193481445,
          "response": "MLX-VLM inference failed: input operand has more dimensions than allowed by the axis remapping",
          "image_info": {
            "original_size": [
              336,
              336
            ],
            "processed_size": [
              336,
              336
            ],
            "mode": "RGB",
            "file_size": 11823
          },
          "error": null,
          "unified_test": true,
          "generation_params": {
            "max_new_tokens": 100,
            "do_sample": false
          },
          "timeout_used": 180
        },
        "test_image.png": {
          "inference_time": 0.027998924255371094,
          "response": "MLX-VLM inference failed: input operand has more dimensions than allowed by the axis remapping",
          "image_info": {
            "original_size": [
              336,
              336
            ],
            "processed_size": [
              336,
              336
            ],
            "mode": "RGB",
            "file_size": 2305
          },
          "error": null,
          "unified_test": true,
          "generation_params": {
            "max_new_tokens": 100,
            "do_sample": false
          },
          "timeout_used": 180
        }
      },
      "total_inference_time": 5.921239852905273,
      "successful_inferences": 3,
      "failed_inferences": 0,
      "avg_inference_time": 1.973746617635091,
      "memory_after_cleanup": 0.4920196533203125
    }
  }
}