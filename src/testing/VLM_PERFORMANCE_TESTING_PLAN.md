# VLM Performance Testing Plan

## ğŸ¯ **Testing Summary** (Latest Update)
> âœ… **Testing Complete**: 5 models, 4 successful (80% success rate)  
> ğŸ† **Major Breakthrough**: Phi-3.5-Vision MLX optimization success, from complete failure to best performance  
> âš¡ **Fastest Loading**: Phi-3.5-Vision-MLX (1.97s)  
> ğŸ’¨ **Fastest Inference**: Moondream2 (5.86s)  
> ğŸ“¸ **Multi-Image Support**: Automatic detection and testing of multiple images  

## ğŸ“‹ Testing Objectives

Comprehensive testing of 5 vision-language models, recording basic performance metrics and response results. Using MacBook Air M3 (16GB) environment, supporting single or multiple image testing.

## ğŸ¯ Test Model List

1. **SmolVLM2-500M-Video-Instruct** â†’ `HuggingFaceTB/SmolVLM2-500M-Video-Instruct`
2. **SmolVLM-500M-Instruct** â†’ `HuggingFaceTB/SmolVLM-500M-Instruct`
3. **Moondream2** â†’ `vikhyatk/moondream2`
4. **LLaVA-v1.5-7B** â†’ `llava-hf/llava-1.5-7b-hf`
5. **Phi-3.5-Vision-Instruct** â†’ `lokinfey/Phi-3.5-vision-mlx-int4` (MLX-optimized for Apple Silicon)

> Loading methods reference `active_model.md`

## ğŸ“Š Recorded Test Metrics

### â±ï¸ **Time Metrics**
- **Model Loading Time**: Time required to load model
- **Inference Time**: Processing time per image
- **Total Test Time**: Complete testing duration

### ğŸ’¾ **Memory Metrics**  
- **Memory Before Loading**: Memory usage before model loading
- **Memory After Loading**: Memory usage after model loading
- **Memory Difference**: Memory occupied by the model

### ğŸ“ **Result Recording**
- **Model Response**: Complete response text for each image
- **Image Information**: Image filename, size, resolution
- **Error Recording**: Detailed error information if errors occur

## ğŸ“¸ Test Configuration

### **ğŸ“ Unified Test Conditions** âœ¨
To ensure fair comparison, all models use unified test conditions:

- **ğŸ–¼ï¸ Image Preprocessing**: Unified scaling to maximum 1024 pixels, preserving aspect ratio
- **ğŸ’¬ Prompt**: All models use the same prompt
- **âš™ï¸ Generation Parameters**: `max_new_tokens: 100, do_sample: false`
- **ğŸ·ï¸ Image Format**: Local images use `{"type": "image", "image": image}` format

### **Test Images** ğŸ“¸
- **Image Location**: `src/testing/testing_material/images/`
- **Multi-Image Support**: Automatically detects all images in directory, tests each individually
- **Quantity**: Based on available image count (currently supports 1-N images)
- **Format**: Supports JPG, JPEG, PNG, BMP and other common formats
- **Processing**: Automatic scaling to unified size (maximum 1024 pixels)
- **Data Recording**: Each image independently records inference time, response content, image information

### **Test Prompt**
Using unified prompt for all image testing:
```
"Describe what you see in this image in detail."
```

## ğŸ› ï¸ Implementation Files

### ğŸ“ **Simple File Structure**
```
src/testing/
â”œâ”€â”€ VLM_PERFORMANCE_TESTING_PLAN.md     # Test plan
â”œâ”€â”€ vlm_tester.py                        # Main testing program
â”œâ”€â”€ testing_material/
â”‚   â””â”€â”€ images/                          # Test images (user provided)
â””â”€â”€ results/
    â””â”€â”€ test_results.json                # Test result records
```

### ğŸ”§ **Main Program Features**
`vlm_tester.py` includes:
- **Sequential model loading** (avoiding memory overflow)
- **Complete memory cleanup after testing**
- Reading test images
- Recording time and memory usage
- Saving all results to JSON files

### âš ï¸ **Memory Management Strategy** âœ¨
Due to M3 MacBook Air 16GB memory limitations:
1. **Sequential Loading**: Load only one model at a time
2. **Complete Testing**: Finish all image tests for that model
3. **Memory Cleanup**: `del model, gc.collect(), torch.mps.empty_cache()`
4. **Load Next**: Clean up before loading next model

### â±ï¸ **Timeout Mechanism** âœ¨
Setting reasonable timeouts based on different model technical characteristics:
- **Small Models** (SmolVLM series, Moondream2): 60 seconds
- **Medium Models** (Phi-3.5-Vision MLX): 180 seconds (significantly improved with MLX optimization)
- **Large Models** (LLaVA-v1.5-7B): 180 seconds (CPU inference requires more time)

### ğŸ”§ **Known Limitations & Solutions** âœ¨
- **LLaVA-v1.5-7B**: Extremely slow CPU inference, often times out (180 seconds)
- **Phi-3.5-Vision**: âœ… **MLX Optimization Success!** Improved from timeout failure to fastest loading (1.97s)
  - **Required**: `pip install mlx-vlm` for Apple Silicon M1/M2/M3
  - **Effect**: From complete failure to 100% success, loading time reduced by 98%
- **Moondream2**: Uses special API, cannot fully unify parameter control (but doesn't affect comparison fairness)

## ğŸ“‹ Implementation Steps

1. **Create Test Program** - Write `vlm_tester.py`
2. **Test Model Loading** - Confirm all 5 models can load normally
3. **Execute Testing** - Test all images
4. **Record Results** - Save all data to JSON files

## ğŸ“Š Result Format âœ¨

Test results will be saved in JSON format, including unified test markers:

```json
{
  "test_timestamp": "2025-01-XX XX:XX:XX",
  "system_info": {
    "device": "MacBook Air M3",
    "memory": "16GB",
    "mps_available": true
  },
  "models": {
    "model_name": {
      "model_id": "actual/model/path",
      "load_time": 10.5,
      "memory_before": 8.2,
      "memory_after": 12.8,
      "memory_diff": 4.6,
      "memory_after_cleanup": 8.5,
      "successful_inferences": 3,
      "failed_inferences": 0,
      "avg_inference_time": 6.2,
      "images": {
        "test_image.png": {
          "inference_time": 13.00,
          "response": "The image shows a simple graphic representation...",
          "image_info": {
            "original_size": [336, 336],
            "processed_size": [336, 336],
            "mode": "RGB",
            "file_size": 2305
          },
          "error": null,
          "unified_test": true,
          "generation_params": {
            "max_new_tokens": 100,
            "do_sample": false
          },
          "timeout_used": 180
        },
        "IMG_0119.JPG": {
          "inference_time": 12.19,
          "response": "This image shows a Shiba Inu dog...",
          "image_info": {
            "original_size": [960, 1707],
            "processed_size": [575, 1024],
            "mode": "RGB",
            "file_size": 222091
          },
          "error": null,
          "unified_test": true
        }
      },
      "total_inference_time": 25.19,
      "successful_inferences": 2,
      "failed_inferences": 0,
      "avg_inference_time": 12.60
    }
  }
}
```

## ğŸ† Actual Test Results âœ¨
> ğŸ“… **Latest Test**: 2025-07-08 21:43:32  
> ğŸ“¸ **Test Images**: 1 image (`test_image.png` - geometric shapes)

### âœ… **Successful Models (4/5)** ğŸ‰
| Rank | Model | Load Time | Inference Time | Memory Usage | Success Rate |
|------|-------|-----------|----------------|--------------|--------------|
| ğŸ¥‡ | **Phi-3.5-Vision-MLX** | **1.97s** | 13.00s | -3.04GB | 100% |
| ğŸ¥ˆ | **Moondream2** | 5.24s | **5.86s** | -1.07GB | 100% |
| ğŸ¥‰ | **SmolVLM-500M-Instruct** | 3.99s | 11.77s | -0.13GB | 100% |
| 4ï¸âƒ£ | **SmolVLM2-500M-Video** | 2.65s | 15.40s | +0.08GB | 100% |

### âŒ **Failed Models (1/5)**
- **LLaVA-v1.5-7B**: Loading successful (2.23s), but inference timeout (180 seconds) - CPU inference too slow

### ğŸ† **MLX Optimization Success Story** 
**Phi-3.5-Vision's Amazing Transformation**:
- **Before (Transformers)**: 135s+ loading timeout â†’ 100% failure
- **Now (MLX)**: 1.97s fastest loading â†’ 100% success 
- **Improvement**: Loading speed improved **98%+**, from unusable to **best performance**

### ğŸ“ **Key Findings**
1. **ğŸš€ MLX Framework Breakthrough**: Revolutionary VLM performance improvement on Apple Silicon
2. **âš¡ Fastest Loading**: Phi-3.5-Vision-MLX (1.97s) surpasses all models
3. **ğŸ’¨ Fastest Inference**: Moondream2 (5.86s) leads in inference speed
4. **ğŸ’¾ Memory Efficiency**: MLX models use memory more efficiently
5. **ğŸ“Š Overall Success Rate**: 80% (4/5) - exceeds expectations
6. **âš™ï¸ Unified Testing**: Successfully achieved fair comparison environment

## âœ… Usage Instructions

### ğŸš€ **Basic Test Commands**
1. **Single Model Test**: `python vlm_tester.py "Model Name"`
   - Example: `python vlm_tester.py "Phi-3.5-Vision-Instruct"`
2. **Full Test**: `python vlm_tester.py`
3. **View Results**: Check JSON files in `results/` directory

### ğŸ“¸ **Multi-Image Test Support**
- **Automatic Multi-Image Testing**: Program automatically detects all images in `testing_material/images/`
- **Result Format**: Each image independently recorded in JSON `images` field
- **Statistics**: Automatically calculates total inference time, success/failure counts, average inference time

### ğŸ“Š **Result Files**
- **Main Results**: `test_results_YYYYMMDD_HHMMSS.json`
- **Single Model Results**: `test_results_single_[Model Name].json`
- **Intermediate Results**: `test_results_intermediate_[Model Name].json` (prevents test interruption)

### âš ï¸ **Pre-usage Preparation**
1. **Activate Virtual Environment**: `source ../../ai_vision_env/bin/activate`
2. **Install MLX-VLM** (Required for Apple Silicon): `pip install mlx-vlm`
3. **Prepare Test Images**: Place images in `testing_material/images/` directory 