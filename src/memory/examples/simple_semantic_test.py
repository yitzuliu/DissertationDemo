"""
ç°¡åŒ–çš„èªç¾©æœç´¢æ¸¬è©¦

é©—è­‰ChromaDBèªç¾©æœç´¢æ˜¯å¦æŒ‰é æœŸå·¥ä½œ
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '../../..'))

def test_embedding_similarity():
    """æ¸¬è©¦åµŒå…¥æ¨¡å‹çš„èªç¾©ç†è§£èƒ½åŠ›"""
    from sentence_transformers import SentenceTransformer
    
    print("ğŸ§  æ¸¬è©¦åµŒå…¥æ¨¡å‹çš„èªç¾©ç†è§£...")
    
    # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
    model = SentenceTransformer('all-MiniLM-L6-v2')
    
    # æ¸¬è©¦æ–‡æœ¬
    texts = [
        "æ¡Œä¸Šæœ‰èºçµ²åˆ€å’Œæ‰³æ‰‹",
        "æˆ‘çœ‹åˆ°ä¸€äº›å·¥å…·",
        "Pythonæ˜¯ç·¨ç¨‹èªè¨€",
        "ç”¨æˆ¶åœ¨å¯«ä»£ç¢¼",
        "æ¡Œä¸Šæœ‰å’–å•¡"
    ]
    
    # ç”ŸæˆåµŒå…¥
    embeddings = model.encode(texts)
    
    # æ¸¬è©¦æŸ¥è©¢
    queries = [
        "æ¡Œä¸Šæœ‰ä»€éº¼å·¥å…·ï¼Ÿ",
        "ç”¨æˆ¶åœ¨åšä»€éº¼ç·¨ç¨‹å·¥ä½œï¼Ÿ",
        "æœ‰ä»€éº¼é£²æ–™å—ï¼Ÿ"
    ]
    
    query_embeddings = model.encode(queries)
    
    # è¨ˆç®—ç›¸ä¼¼åº¦
    from sklearn.metrics.pairwise import cosine_similarity
    import numpy as np
    
    print("\nğŸ“Š èªç¾©ç›¸ä¼¼åº¦æ¸¬è©¦çµæœ:")
    print("=" * 50)
    
    for i, query in enumerate(queries):
        print(f"\nğŸ” æŸ¥è©¢: '{query}'")
        
        # è¨ˆç®—èˆ‡æ‰€æœ‰æ–‡æœ¬çš„ç›¸ä¼¼åº¦
        similarities = cosine_similarity([query_embeddings[i]], embeddings)[0]
        
        # æ’åºä¸¦é¡¯ç¤ºæœ€ç›¸é—œçš„çµæœ
        sorted_indices = np.argsort(similarities)[::-1]
        
        for j, idx in enumerate(sorted_indices[:3]):
            similarity = similarities[idx]
            print(f"   {j+1}. [{similarity:.3f}] {texts[idx]}")
    
    print("\nâœ… èªç¾©æœç´¢æ¸¬è©¦å®Œæˆï¼")
    print("ğŸ¯ çµæœé¡¯ç¤ºæ¨¡å‹èƒ½å¤ ç†è§£èªç¾©é—œä¿‚")

if __name__ == "__main__":
    try:
        test_embedding_similarity()
    except ImportError as e:
        print(f"âŒ å°å…¥éŒ¯èª¤: {e}")
        print("è«‹ç¢ºä¿å·²å®‰è£ sentence-transformers å’Œ scikit-learn")
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")