#!/usr/bin/env python3
"""
æ¸¬è©¦é‡å¯«çš„ LLaVA-MLX å¯¦ç¾
"""

import sys
import os
sys.path.append('src/testing/vlm')

def test_llava_loading():
    """æ¸¬è©¦ LLaVA æ¨¡å‹åŠ è¼‰"""
    print("ğŸ§ª æ¸¬è©¦ LLaVA æ¨¡å‹åŠ è¼‰...")
    
    try:
        from vlm_tester import VLMModelLoader
        
        # æ¸¬è©¦åŠ è¼‰ LLaVA
        print("ğŸ“¥ åŠ è¼‰ LLaVA-MLX æ¨¡å‹...")
        model, processor = VLMModelLoader.load_llava_mlx()
        
        print("âœ… LLaVA æ¨¡å‹åŠ è¼‰æˆåŠŸ!")
        print(f"   æ¨¡å‹é¡å‹: {type(model)}")
        print(f"   è™•ç†å™¨é¡å‹: {type(processor)}")
        print(f"   MLX æ¨™è¨˜: {hasattr(model, '_is_mlx_model')}")
        
        return True, model, processor
        
    except Exception as e:
        print(f"âŒ LLaVA æ¨¡å‹åŠ è¼‰å¤±æ•—: {e}")
        return False, None, None

def test_llava_inference(model, processor):
    """æ¸¬è©¦ LLaVA æ¨ç†"""
    print("\nğŸ§ª æ¸¬è©¦ LLaVA æ¨ç†...")
    
    try:
        from vlm_tester import VLMTester
        from PIL import Image
        import tempfile
        
        # å‰µå»ºæ¸¬è©¦åœ–ç‰‡
        test_image = Image.new('RGB', (224, 224), color='red')
        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp_file:
            temp_image_path = tmp_file.name
            test_image.save(temp_image_path)
        
        # å‰µå»ºæ¸¬è©¦å™¨
        tester = VLMTester()
        
        # æ¸¬è©¦åœ–ç‰‡æ¨ç†
        print("ğŸ–¼ï¸ æ¸¬è©¦åœ–ç‰‡æ¨ç†...")
        image_result = tester.test_single_image(
            model, processor, 
            temp_image_path, 
            "LLaVA-v1.6-Mistral-7B-MLX"
        )
        
        print(f"   æ¨ç†æ™‚é–“: {image_result.get('inference_time', 0):.2f} ç§’")
        print(f"   å›æ‡‰é•·åº¦: {len(image_result.get('response', ''))}")
        print(f"   éŒ¯èª¤: {image_result.get('error', 'None')}")
        
        # æ¸¬è©¦æ–‡å­—æ¨ç†
        print("\nğŸ”¤ æ¸¬è©¦æ–‡å­—æ¨ç†...")
        text_response = tester._test_llava_text_only(
            model, processor, 
            "What is the capital of France?"
        )
        
        print(f"   æ–‡å­—å›æ‡‰: {text_response[:100]}...")
        
        # æ¸…ç†
        os.remove(temp_image_path)
        
        return True
        
    except Exception as e:
        print(f"âŒ LLaVA æ¨ç†æ¸¬è©¦å¤±æ•—: {e}")
        return False

def test_llava_full_workflow():
    """æ¸¬è©¦å®Œæ•´çš„ LLaVA å·¥ä½œæµç¨‹"""
    print("\nğŸ§ª æ¸¬è©¦å®Œæ•´ LLaVA å·¥ä½œæµç¨‹...")
    
    try:
        from vlm_tester import VLMTester
        
        # å‰µå»ºæ¸¬è©¦å™¨
        tester = VLMTester()
        
        # ç²å– LLaVA é…ç½®
        llava_config = tester.models_config.get("LLaVA-v1.6-Mistral-7B-MLX")
        if not llava_config:
            print("âŒ LLaVA é…ç½®æœªæ‰¾åˆ°")
            return False
        
        print("ğŸ“‹ LLaVA é…ç½®:")
        print(f"   æ¨¡å‹ ID: {llava_config['model_id']}")
        print(f"   å„ªå…ˆç´š: {llava_config['priority']}")
        print(f"   è¨˜æ†¶é«”å¯†é›†: {llava_config['memory_intensive']}")
        
        # æ¸¬è©¦å–®å€‹æ¨¡å‹
        print("\nğŸ”„ é‹è¡Œå–®å€‹æ¨¡å‹æ¸¬è©¦...")
        model_results = tester.test_single_model("LLaVA-v1.6-Mistral-7B-MLX", llava_config)
        
        print("ğŸ“Š æ¸¬è©¦çµæœ:")
        print(f"   åŠ è¼‰æ™‚é–“: {model_results.get('load_time', 0):.2f} ç§’")
        print(f"   æˆåŠŸæ¨ç†: {model_results.get('successful_inferences', 0)}")
        print(f"   å¤±æ•—æ¨ç†: {model_results.get('failed_inferences', 0)}")
        print(f"   æ–‡å­—æ”¯æŒ: {model_results.get('text_only_capability', {}).get('text_only_supported', 'Unknown')}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å®Œæ•´å·¥ä½œæµç¨‹æ¸¬è©¦å¤±æ•—: {e}")
        return False

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ LLaVA-MLX é‡å¯«ç‰ˆæœ¬æ¸¬è©¦")
    print("=" * 50)
    
    # æ¸¬è©¦åŠ è¼‰
    success, model, processor = test_llava_loading()
    if not success:
        print("\nğŸ’¥ LLaVA åŠ è¼‰å¤±æ•—ï¼Œåœæ­¢æ¸¬è©¦")
        return False
    
    # æ¸¬è©¦æ¨ç†
    if not test_llava_inference(model, processor):
        print("\nğŸ’¥ LLaVA æ¨ç†æ¸¬è©¦å¤±æ•—")
        return False
    
    # æ¸¬è©¦å®Œæ•´å·¥ä½œæµç¨‹
    if not test_llava_full_workflow():
        print("\nğŸ’¥ å®Œæ•´å·¥ä½œæµç¨‹æ¸¬è©¦å¤±æ•—")
        return False
    
    print("\nğŸ‰ æ‰€æœ‰ LLaVA æ¸¬è©¦é€šé!")
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)