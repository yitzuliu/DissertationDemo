# AI Manual Assistant æ—¥èªŒç³»çµ±ä½¿ç”¨æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

AI Manual Assistant æ—¥èªŒç³»çµ±æä¾›å®Œæ•´çš„ç³»çµ±è¿½è¹¤å’Œåˆ†æåŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š

- **çµ±ä¸€æ—¥èªŒç®¡ç†**ï¼šå¤šé¡å‹æ—¥èªŒçš„çµ±ä¸€è¨˜éŒ„å’Œç®¡ç†
- **æµç¨‹è¿½è¹¤**ï¼šç«¯åˆ°ç«¯æµç¨‹çš„å®Œæ•´è¿½è¹¤
- **æ€§èƒ½ç›£æ§**ï¼šç³»çµ±æ€§èƒ½çš„å¯¦æ™‚ç›£æ§
- **ç•°å¸¸æª¢æ¸¬**ï¼šè‡ªå‹•æª¢æ¸¬ç³»çµ±ç•°å¸¸å’Œå•é¡Œ
- **åˆ†æå·¥å…·**ï¼šå¼·å¤§çš„æ—¥èªŒåˆ†æå’Œè¨ºæ–·å·¥å…·

## ğŸ—ï¸ ç³»çµ±æ¶æ§‹

### æ ¸å¿ƒçµ„ä»¶

1. **LogManager** (`src/logging/log_manager.py`)
   - çµ±ä¸€æ—¥èªŒç®¡ç†å™¨
   - å”¯ä¸€IDç”Ÿæˆ
   - å¤šé¡å‹æ—¥èªŒè¨˜éŒ„

2. **FlowTracker** (`src/logging/flow_tracker.py`)
   - æµç¨‹è¿½è¹¤å™¨
   - ç«¯åˆ°ç«¯æµç¨‹ç®¡ç†
   - æ™‚é–“ç·šè¨˜éŒ„

3. **LogAnalyzer** (`tools/log_analyzer.py`)
   - æ—¥èªŒåˆ†æå·¥å…·
   - äº‹ä»¶é—œè¯åˆ†æ
   - è³‡æ–™å®Œæ•´æ€§æª¢æŸ¥

4. **LogDiagnostics** (`tools/log_diagnostics.py`)
   - ç³»çµ±è¨ºæ–·å·¥å…·
   - æ€§èƒ½ç›£æ§
   - ç•°å¸¸æª¢æ¸¬

### æ—¥èªŒé¡å‹

- **ç³»çµ±æ—¥èªŒ** (`system_*.log`)ï¼šç³»çµ±å•Ÿå‹•ã€é—œé–‰ã€éŒ¯èª¤ç­‰
- **è¦–è¦ºæ—¥èªŒ** (`visual_*.log`)ï¼šVLMè™•ç†ã€åœ–åƒæ•ç²ç­‰
- **ä½¿ç”¨è€…æ—¥èªŒ** (`user_*.log`)ï¼šä½¿ç”¨è€…æŸ¥è©¢ã€å›æ‡‰ç­‰
- **æµç¨‹è¿½è¹¤** (`flow_tracking_*.log`)ï¼šæµç¨‹é–‹å§‹ã€æ­¥é©Ÿã€çµæŸ

## ğŸš€ å¿«é€Ÿé–‹å§‹

### 1. åŸºæœ¬ä½¿ç”¨

```python
from src.logging.log_manager import get_log_manager

# ç²å–æ—¥èªŒç®¡ç†å™¨
log_manager = get_log_manager()

# è¨˜éŒ„ä½¿ç”¨è€…æŸ¥è©¢
query_id = log_manager.generate_query_id()
request_id = log_manager.generate_request_id()

log_manager.log_user_query(
    query_id=query_id,
    request_id=request_id,
    question="æˆ‘éœ€è¦ä»€éº¼å·¥å…·ï¼Ÿ",
    language="zh"
)

# è¨˜éŒ„æŸ¥è©¢åˆ†é¡
log_manager.log_query_classify(
    query_id=query_id,
    query_type="required_tools",
    confidence=0.95
)

# è¨˜éŒ„æŸ¥è©¢å›æ‡‰
log_manager.log_query_response(
    query_id=query_id,
    response="æ‚¨éœ€è¦ï¼šæ¿¾ç´™ã€æ»´æ¿¾å™¨ã€ç†±æ°´ã€æ¯å­ã€‚",
    duration=1.2
)
```

### 2. æµç¨‹è¿½è¹¤

```python
from src.logging.flow_tracker import get_flow_tracker, FlowType, FlowStep, FlowStatus

# ç²å–æµç¨‹è¿½è¹¤å™¨
flow_tracker = get_flow_tracker()

# é–‹å§‹æµç¨‹
flow_id = flow_tracker.start_flow(
    FlowType.USER_QUERY,
    metadata={"user_id": "user123"}
)

# æ·»åŠ æµç¨‹æ­¥é©Ÿ
flow_tracker.add_flow_step(
    flow_id=flow_id,
    step=FlowStep.QUERY_RECEIVED,
    related_ids={"query_id": query_id}
)

flow_tracker.add_flow_step(
    flow_id=flow_id,
    step=FlowStep.QUERY_CLASSIFICATION,
    related_ids={"query_id": query_id},
    metadata={"confidence": 0.95}
)

# çµæŸæµç¨‹
flow_tracker.end_flow(
    flow_id=flow_id,
    status=FlowStatus.SUCCESS,
    final_metadata={"response_time": 1.2}
)
```

## ğŸ“Š æ—¥èªŒåˆ†æ

### 1. åŸºæœ¬åˆ†æ

```bash
# ç”Ÿæˆç¶œåˆå ±å‘Š
python tools/log_analyzer.py --report-type comprehensive --output report.json

# åˆ†æç‰¹å®šæ™‚é–“ç¯„åœ
python tools/log_analyzer.py --start-time "2025-01-30 09:00:00" --end-time "2025-01-30 18:00:00"

# åˆ†æç‰¹å®šæŸ¥è©¢
python tools/log_analyzer.py --query-id query_1234567890_abcdef12
```

### 2. ç³»çµ±è¨ºæ–·

```bash
# åŸ·è¡Œç¶œåˆè¨ºæ–·
python tools/log_diagnostics.py --diagnostic-type comprehensive --output diagnostics.json

# åªæª¢æŸ¥VLMå¤±æ•—
python tools/log_diagnostics.py --diagnostic-type vlm

# æª¢æŸ¥æŸ¥è©¢åˆ†é¡æº–ç¢ºåº¦
python tools/log_diagnostics.py --diagnostic-type query
```

### 3. ç¨‹å¼åŒ–åˆ†æ

```python
from tools.log_analyzer import LogAnalyzer
from tools.log_diagnostics import LogDiagnostics

# å‰µå»ºåˆ†æå™¨
analyzer = LogAnalyzer("logs")
diagnostics = LogDiagnostics("logs")

# åˆ†æäº‹ä»¶æµç¨‹
flow_analysis = analyzer.analyze_event_flow(query_id="query_123")
print(f"äº‹ä»¶æ•¸é‡: {flow_analysis['total_events']}")
print(f"æ™‚é–“è·¨åº¦: {flow_analysis['time_span']}ç§’")

# æª¢æŸ¥è³‡æ–™å®Œæ•´æ€§
integrity_report = analyzer.check_data_integrity()
print(f"ç¸½æŸ¥è©¢æ•¸: {integrity_report['total_queries']}")
print(f"ä¸å®Œæ•´æŸ¥è©¢: {len(integrity_report['incomplete_queries'])}")

# åŸ·è¡Œè¨ºæ–·
diagnostics_report = diagnostics.run_comprehensive_diagnostics()
print(f"æ•´é«”ç‹€æ…‹: {diagnostics_report['overall_status']}")
for recommendation in diagnostics_report['recommendations']:
    print(f"å»ºè­°: {recommendation}")
```

## ğŸ”§ é…ç½®å’Œè‡ªå®šç¾©

### 1. æ—¥èªŒç›®éŒ„é…ç½®

```python
# è‡ªå®šç¾©æ—¥èªŒç›®éŒ„
log_manager = get_log_manager("custom_logs")

# åˆ†æè‡ªå®šç¾©ç›®éŒ„
analyzer = LogAnalyzer("custom_logs")
```

### 2. è¨ºæ–·é–¾å€¼èª¿æ•´

```python
from tools.log_diagnostics import LogDiagnostics

# å‰µå»ºè‡ªå®šç¾©è¨ºæ–·å™¨
diagnostics = LogDiagnostics("logs")

# èª¿æ•´é–¾å€¼
diagnostics.thresholds['vlm_failure_rate'] = 0.05  # 5%å¤±æ•—ç‡
diagnostics.thresholds['query_response_time_p95'] = 30.0  # 30mså›æ‡‰æ™‚é–“
diagnostics.thresholds['error_rate'] = 0.02  # 2%éŒ¯èª¤ç‡
```

### 3. æ—¥èªŒæ ¼å¼è‡ªå®šç¾©

æ—¥èªŒæ ¼å¼åœ¨ `LogManager` ä¸­å®šç¾©ï¼Œå¯ä»¥ä¿®æ”¹ `_format_log_message` æ–¹æ³•ï¼š

```python
def _format_log_message(self, event_type: str, **kwargs) -> str:
    """è‡ªå®šç¾©æ—¥èªŒæ ¼å¼"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S,%f")[:-3]
    data_str = " ".join([f"{k}={v}" for k, v in kwargs.items()])
    return f"{timestamp} [INFO] [{event_type}] {data_str}"
```

## ğŸ“ˆ ç›£æ§å’Œè­¦å ±

### 1. å¯¦æ™‚ç›£æ§

```python
import time
from tools.log_diagnostics import LogDiagnostics

diagnostics = LogDiagnostics("logs")

while True:
    # æ¯åˆ†é˜æª¢æŸ¥ä¸€æ¬¡
    report = diagnostics.run_comprehensive_diagnostics()
    
    if report['overall_status'] == 'CRITICAL':
        print("ğŸš¨ ç³»çµ±ç‹€æ…‹å±æ€¥ï¼")
        for recommendation in report['recommendations']:
            print(f"  - {recommendation}")
    
    elif report['overall_status'] == 'WARNING':
        print("âš ï¸ ç³»çµ±ç‹€æ…‹è­¦å‘Š")
        for recommendation in report['recommendations']:
            print(f"  - {recommendation}")
    
    time.sleep(60)  # ç­‰å¾…60ç§’
```

### 2. æ€§èƒ½ç›£æ§

```python
from tools.log_diagnostics import LogDiagnostics

diagnostics = LogDiagnostics("logs")

# ç›£æ§æŸ¥è©¢æ€§èƒ½
performance = diagnostics.monitor_system_performance()
print(f"å¹³å‡å›æ‡‰æ™‚é–“: {performance['query_performance']['average']:.1f}ms")
print(f"95%å›æ‡‰æ™‚é–“: {performance['query_performance']['p95']:.1f}ms")
print(f"éŒ¯èª¤ç‡: {performance['error_rate']:.2%}")

# æª¢æŸ¥æ€§èƒ½å•é¡Œ
for issue in performance['performance_issues']:
    print(f"æ€§èƒ½å•é¡Œ: {issue['description']}")
```

## ğŸ› æ•…éšœæ’é™¤

### 1. å¸¸è¦‹å•é¡Œ

**å•é¡Œï¼šæ—¥èªŒæª”æ¡ˆç„¡æ³•å¯«å…¥**
```bash
# æª¢æŸ¥æ¬Šé™
ls -la logs/
chmod 755 logs/
chmod 644 logs/*.log
```

**å•é¡Œï¼šæ—¥èªŒåˆ†æå·¥å…·ç„¡æ³•æ‰¾åˆ°æª”æ¡ˆ**
```bash
# æª¢æŸ¥æ—¥èªŒç›®éŒ„
python tools/log_analyzer.py --log-dir /path/to/logs

# æª¢æŸ¥æª”æ¡ˆå­˜åœ¨
ls -la logs/
```

**å•é¡Œï¼šè¨ºæ–·å·¥å…·å ±å‘ŠéŒ¯èª¤**
```bash
# æª¢æŸ¥æ—¥èªŒæ ¼å¼
head -5 logs/user_20250130.log

# é‡æ–°ç”Ÿæˆå ±å‘Š
python tools/log_diagnostics.py --diagnostic-type comprehensive
```

### 2. èª¿è©¦æ¨¡å¼

```python
import logging

# å•Ÿç”¨èª¿è©¦æ—¥èªŒ
logging.basicConfig(level=logging.DEBUG)

# æ¸¬è©¦æ—¥èªŒè¨˜éŒ„
from src.logging.log_manager import get_log_manager
log_manager = get_log_manager()

# è¨˜éŒ„æ¸¬è©¦æ—¥èªŒ
log_manager.log_user_query(
    query_id="test_query",
    request_id="test_request",
    question="æ¸¬è©¦æŸ¥è©¢",
    language="zh"
)
```

### 3. æ€§èƒ½èª¿å„ª

```python
# æ‰¹é‡æ—¥èªŒè¨˜éŒ„
import time

start_time = time.time()
for i in range(1000):
    log_manager.log_user_query(
        query_id=f"query_{i}",
        request_id=f"req_{i}",
        question=f"æŸ¥è©¢ {i}",
        language="zh"
    )

end_time = time.time()
print(f"1000æ¬¡æ—¥èªŒè¨˜éŒ„è€—æ™‚: {end_time - start_time:.3f}ç§’")
```

## ğŸ“š é€²éšåŠŸèƒ½

### 1. è‡ªå®šç¾©åˆ†æ

```python
from tools.log_analyzer import LogAnalyzer

analyzer = LogAnalyzer("logs")

# è‡ªå®šç¾©äº‹ä»¶éæ¿¾
def custom_filter(log_entry):
    return log_entry['event_type'] == 'USER_QUERY' and 'error' in log_entry['data'].get('question', '').lower()

# è¼‰å…¥ä¸¦éæ¿¾æ—¥èªŒ
logs = analyzer.load_logs()
filtered_logs = [log for log in logs if custom_filter(log)]

print(f"æ‰¾åˆ° {len(filtered_logs)} å€‹åŒ…å«éŒ¯èª¤çš„æŸ¥è©¢")
```

### 2. çµ±è¨ˆåˆ†æ

```python
from collections import Counter
from tools.log_analyzer import LogAnalyzer

analyzer = LogAnalyzer("logs")
logs = analyzer.load_logs()

# çµ±è¨ˆäº‹ä»¶é¡å‹
event_types = Counter(log['event_type'] for log in logs)
print("äº‹ä»¶é¡å‹çµ±è¨ˆ:")
for event_type, count in event_types.most_common():
    print(f"  {event_type}: {count}")

# çµ±è¨ˆéŒ¯èª¤
errors = [log for log in logs if log['level'] == 'ERROR']
print(f"ç¸½éŒ¯èª¤æ•¸: {len(errors)}")
```

### 3. å ±å‘Šç”Ÿæˆ

```python
from tools.log_analyzer import LogAnalyzer
from datetime import datetime, timedelta

analyzer = LogAnalyzer("logs")

# ç”Ÿæˆæ¯æ—¥å ±å‘Š
end_time = datetime.now()
start_time = end_time - timedelta(days=1)

report = analyzer.generate_report(
    report_type='comprehensive',
    start_time=start_time,
    end_time=end_time
)

# å°å‡ºå ±å‘Š
analyzer.export_report(report, f"daily_report_{end_time.strftime('%Y%m%d')}.json")
```

## ğŸ”— æ•´åˆæŒ‡å—

### 1. èˆ‡ç¾æœ‰ç³»çµ±æ•´åˆ

```python
# åœ¨ç¾æœ‰çš„æŸ¥è©¢è™•ç†ä¸­æ·»åŠ æ—¥èªŒ
from src.logging.log_manager import get_log_manager

log_manager = get_log_manager()

def process_user_query(query: str):
    query_id = log_manager.generate_query_id()
    request_id = log_manager.generate_request_id()
    
    # è¨˜éŒ„æŸ¥è©¢é–‹å§‹
    log_manager.log_user_query(
        query_id=query_id,
        request_id=request_id,
        question=query,
        language="zh"
    )
    
    try:
        # è™•ç†æŸ¥è©¢
        result = your_query_processor(query)
        
        # è¨˜éŒ„åˆ†é¡
        log_manager.log_query_classify(
            query_id=query_id,
            query_type=result.type,
            confidence=result.confidence
        )
        
        # è¨˜éŒ„å›æ‡‰
        log_manager.log_query_response(
            query_id=query_id,
            response=result.response,
            duration=result.processing_time
        )
        
        return result
        
    except Exception as e:
        # è¨˜éŒ„éŒ¯èª¤
        log_manager.get_logger(LogType.SYSTEM).error(f"æŸ¥è©¢è™•ç†å¤±æ•—: {e}")
        raise
```

### 2. èˆ‡ç›£æ§ç³»çµ±æ•´åˆ

```python
# å®šæœŸå¥åº·æª¢æŸ¥
import schedule
import time
from tools.log_diagnostics import LogDiagnostics

def health_check():
    diagnostics = LogDiagnostics("logs")
    report = diagnostics.run_comprehensive_diagnostics()
    
    if report['overall_status'] != 'NORMAL':
        # ç™¼é€è­¦å ±
        send_alert(report)
    
    return report

# æ¯5åˆ†é˜åŸ·è¡Œä¸€æ¬¡å¥åº·æª¢æŸ¥
schedule.every(5).minutes.do(health_check)

while True:
    schedule.run_pending()
    time.sleep(1)
```

## ğŸ“ æ”¯æ´å’Œè¯ç¹«

å¦‚æœæ‚¨åœ¨ä½¿ç”¨æ—¥èªŒç³»çµ±æ™‚é‡åˆ°å•é¡Œï¼Œè«‹ï¼š

1. æª¢æŸ¥æœ¬æŒ‡å—çš„æ•…éšœæ’é™¤éƒ¨åˆ†
2. æŸ¥çœ‹æ—¥èªŒæª”æ¡ˆä¸­çš„éŒ¯èª¤ä¿¡æ¯
3. é‹è¡Œè¨ºæ–·å·¥å…·ç²å–è©³ç´°å ±å‘Š
4. è¯ç¹«é–‹ç™¼åœ˜éšŠæä¾›è©³ç´°çš„éŒ¯èª¤ä¿¡æ¯

---

**ç‰ˆæœ¬**: 1.0  
**æœ€å¾Œæ›´æ–°**: 2025-01-30  
**ä½œè€…**: AI Manual Assistant é–‹ç™¼åœ˜éšŠ 