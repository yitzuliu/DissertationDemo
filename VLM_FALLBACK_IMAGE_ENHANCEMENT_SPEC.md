# VLM Fallback åœ–ç‰‡å‚³é€åŠŸèƒ½å¢å¼·è¦æ ¼

## ğŸ“‹ é …ç›®æ¦‚è¿°

**ç›®æ¨™**ï¼šæ“´å±• VLM Fallback ç³»çµ±ï¼Œä½¿å…¶èƒ½å¤ åœ¨æŸ¥è©¢åˆ†é¡ä¿¡å¿ƒåº¦ < 0.40 æ™‚ï¼Œå°‡ç•¶å‰åœ–ç‰‡ä¸€ä½µå‚³é€çµ¦ VLMï¼Œæä¾›æ›´è±å¯Œçš„è¦–è¦ºä¸Šä¸‹æ–‡æ”¯æ´ã€‚

**æ ¸å¿ƒæ¦‚å¿µ**ï¼šä½ä¿¡å¿ƒå€¼æŸ¥è©¢ + ç•¶å‰åœ–ç‰‡ â†’ VLM å¤šæ¨¡æ…‹å›æ‡‰ â†’ æ™ºèƒ½è¦–è¦ºæ„ŸçŸ¥å›ç­”

**æ™‚é–“ç·š**ï¼šé è¨ˆ 1 é€±å®Œæˆ
**å„ªå…ˆç´š**ï¼šä¸­é«˜
**ç‹€æ…‹**ï¼šğŸ”„ è¦åŠƒä¸­

## ğŸ—ï¸ ç³»çµ±æ¶æ§‹è¨­è¨ˆ

### 1.1 å¢å¼·æ¶æ§‹åœ–

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚   Backend API   â”‚    â”‚   VLM Service   â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ - Query Input   â”‚â”€â”€â”€â–¶â”‚ - Query Router  â”‚â”€â”€â”€â–¶â”‚ - Model Server  â”‚
â”‚ - Response UI   â”‚    â”‚ - State Tracker â”‚    â”‚ - Direct Query  â”‚
â”‚ - Status Displayâ”‚â—€â”€â”€â”€â”‚ - VLM Fallback  â”‚â—€â”€â”€â”€â”‚ - Response Gen  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ - Image Capture â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   Image System  â”‚
                       â”‚                 â”‚
                       â”‚ - Camera        â”‚
                       â”‚ - Preprocessing â”‚
                       â”‚ - Storage       â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 æ ¸å¿ƒçµ„ä»¶å¢å¼·

#### 1.2.1 åœ–ç‰‡ç²å–ç®¡ç†å™¨ (ImageCaptureManager)
```python
class ImageCaptureManager:
    """ç®¡ç†åœ–ç‰‡ç²å–å’Œé è™•ç†çš„çµ±ä¸€æ¥å£"""
    
    def __init__(self):
        self.camera_manager = None
        self.image_processor = None
        self.last_captured_image = None
        self.image_cache = {}
    
    async def get_current_image(self, model_type: str = None) -> Optional[Dict]:
        """
        ç²å–ç•¶å‰åœ–ç‰‡ï¼Œæ”¯æ´å¤šç¨®ä¾†æº
        """
        # å„ªå…ˆç´š 1ï¼šå¾ç›¸æ©Ÿç²å–å¯¦æ™‚åœ–ç‰‡
        current_image = await self._capture_from_camera()
        if current_image:
            return self._process_for_fallback(current_image, model_type)
        
        # å„ªå…ˆç´š 2ï¼šå¾ç‹€æ…‹è¿½è¹¤å™¨ç²å–æœ€å¾Œè™•ç†çš„åœ–ç‰‡
        last_image = await self._get_last_processed_image()
        if last_image:
            return self._process_for_fallback(last_image, model_type)
        
        # å„ªå…ˆç´š 3ï¼šå¾ç·©å­˜ç²å–
        cached_image = self._get_cached_image()
        if cached_image:
            return self._process_for_fallback(cached_image, model_type)
        
        return None
    
    async def _capture_from_camera(self) -> Optional[bytes]:
        """å¾ç›¸æ©Ÿç³»çµ±ç²å–ç•¶å‰åœ–ç‰‡"""
        try:
            # èª¿ç”¨ç›¸æ©Ÿç®¡ç†å™¨ç²å–ç•¶å‰ç•«é¢
            if self.camera_manager:
                return await self.camera_manager.capture_current_frame()
            return None
        except Exception as e:
            logger.warning(f"Camera capture failed: {e}")
            return None
    
    async def _get_last_processed_image(self) -> Optional[bytes]:
        """å¾ç‹€æ…‹è¿½è¹¤å™¨ç²å–æœ€å¾Œè™•ç†çš„åœ–ç‰‡"""
        try:
            # å¾ç‹€æ…‹è¿½è¹¤å™¨ç²å–æœ€å¾Œçš„åœ–ç‰‡æ•¸æ“š
            state_tracker = get_state_tracker()
            return state_tracker.get_last_processed_image()
        except Exception as e:
            logger.warning(f"Last image retrieval failed: {e}")
            return None
    
    def _process_for_fallback(self, image_data: bytes, model_type: str = None) -> Dict:
        """ç‚º VLM Fallback é è™•ç†åœ–ç‰‡"""
        try:
            # ä½¿ç”¨çµ±ä¸€çš„åœ–ç‰‡é è™•ç†
            processed_image = preprocess_for_model(
                image=image_data,
                model_type=model_type or "smolvlm",  # é»˜èªä½¿ç”¨ smolvlm
                config={},
                return_format='bytes'
            )
            
            # è½‰æ›ç‚º base64
            base64_image = base64.b64encode(processed_image).decode('utf-8')
            
            return {
                "image_data": base64_image,
                "format": "jpeg",
                "size": len(processed_image),
                "processed": True,
                "timestamp": datetime.now()
            }
        except Exception as e:
            logger.error(f"Image processing failed: {e}")
            return None
```

#### 1.2.2 å¢å¼·å‹ VLM Fallback è™•ç†å™¨
```python
class EnhancedVLMFallbackProcessor(VLMFallbackProcessor):
    """å¢å¼·å‹ VLM Fallback è™•ç†å™¨ï¼Œæ”¯æ´åœ–ç‰‡å‚³é€"""
    
    def __init__(self, config: Optional[VLMFallbackConfig] = None):
        super().__init__(config)
        self.image_capture_manager = ImageCaptureManager()
        self.enable_image_fallback = config.enable_image_fallback if config else True
    
    async def process_query_with_image_fallback(self, query: str, state_data: Optional[Dict]) -> Dict:
        """
        è™•ç†æŸ¥è©¢ï¼Œæ”¯æ´åœ–ç‰‡å‚³é€çš„ VLM Fallback
        """
        start_time = time.time()
        self.total_queries += 1
        
        try:
            # æ±ºç­–ï¼šæ˜¯å¦ä½¿ç”¨ VLM Fallback
            should_use_fallback = self.decision_engine.should_use_vlm_fallback(query, state_data)
            
            if should_use_fallback and self.enable_image_fallback:
                # ä½¿ç”¨å¢å¼·å‹ VLM Fallbackï¼ˆåŒ…å«åœ–ç‰‡ï¼‰
                result = await self._execute_enhanced_vlm_fallback(query, state_data)
                self.fallback_queries += 1
            elif should_use_fallback:
                # ä½¿ç”¨å‚³çµ± VLM Fallbackï¼ˆåƒ…æ–‡å­—ï¼‰
                result = await self._execute_vlm_fallback(query, state_data)
                self.fallback_queries += 1
            else:
                # ä½¿ç”¨æ¨¡æ¿å›æ‡‰
                result = self._execute_template_response(query, state_data)
                self.template_queries += 1
            
            # è¨ˆç®—è™•ç†æ™‚é–“
            processing_time = (time.time() - start_time) * 1000
            result.processing_time_ms = processing_time
            
            return self._format_unified_response(result)
            
        except Exception as e:
            self.error_queries += 1
            processing_time = (time.time() - start_time) * 1000
            
            logger.error(f"Enhanced fallback processing failed: {e}")
            
            return self._format_unified_response(self._create_error_result(e, processing_time))
    
    async def _execute_enhanced_vlm_fallback(self, query: str, state_data: Optional[Dict]) -> FallbackResult:
        """
        åŸ·è¡ŒåŒ…å«åœ–ç‰‡çš„ VLM Fallback
        """
        try:
            logger.debug(f"Executing enhanced VLM fallback for query: '{query[:50]}...'")
            
            # ç²å–ç•¶å‰åœ–ç‰‡
            image_data = await self.image_capture_manager.get_current_image()
            
            if image_data:
                # åŸ·è¡ŒåŒ…å«åœ–ç‰‡çš„ VLM Fallback
                vlm_response = await self.prompt_manager.execute_fallback_with_image(
                    query, image_data
                )
                logger.info("Enhanced VLM fallback executed with image")
            else:
                # å›é€€åˆ°ç´”æ–‡å­— Fallback
                vlm_response = await self.prompt_manager.execute_fallback_with_prompt_switch(query)
                logger.info("Enhanced VLM fallback executed without image (fallback to text-only)")
            
            return FallbackResult(
                response_text=vlm_response,
                query_type=self._determine_apparent_query_type(query),
                response_mode="template",  # ä¿æŒé€æ˜æ€§
                confidence=self._calculate_apparent_confidence(state_data),
                processing_time_ms=0.0,
                decision_reason="Enhanced VLM fallback (with image)",
                success=True
            )
            
        except Exception as e:
            logger.error(f"Enhanced VLM fallback execution failed: {e}")
            return self._create_fallback_error_result(e, query)
```

#### 1.2.3 å¢å¼·å‹æç¤ºè©ç®¡ç†å™¨
```python
class EnhancedPromptManager(PromptManager):
    """å¢å¼·å‹æç¤ºè©ç®¡ç†å™¨ï¼Œæ”¯æ´åœ–ç‰‡å‚³é€"""
    
    async def execute_fallback_with_image(self, query: str, image_data: Dict) -> str:
        """
        åŸ·è¡ŒåŒ…å«åœ–ç‰‡çš„ Fallback æµç¨‹
        """
        operation_start = datetime.now()
        
        try:
            logger.info(f"Starting enhanced fallback execution with image for query: '{query[:50]}...'")
            
            # æ­¥é©Ÿ 1ï¼šä¿å­˜ç•¶å‰ç‹€æ…‹è¿½è¹¤æç¤ºè©
            await self._save_current_prompt()
            
            # æ­¥é©Ÿ 2ï¼šåˆ‡æ›åˆ°åŒ…å«åœ–ç‰‡çš„ Fallback æç¤ºè©
            await self._switch_to_image_fallback_prompt(query, image_data)
            
            # æ­¥é©Ÿ 3ï¼šåŸ·è¡ŒåŒ…å«åœ–ç‰‡çš„ VLM æŸ¥è©¢
            response = await self._execute_vlm_query_with_image(query, image_data)
            
            # æ­¥é©Ÿ 4ï¼šæ¢å¾©åŸå§‹æç¤ºè©ï¼ˆé—œéµï¼ï¼‰
            await self._restore_original_prompt()
            
            operation_time = (datetime.now() - operation_start).total_seconds()
            logger.info(f"Enhanced fallback execution completed successfully in {operation_time:.2f}s")
            
            return response
            
        except Exception as e:
            # ç¢ºä¿æç¤ºè©æ¢å¾©
            try:
                await self._restore_original_prompt()
            except Exception as restore_error:
                logger.error(f"Failed to restore prompt after error: {restore_error}")
            
            raise VLMFallbackError(f"Enhanced fallback execution failed: {e}")
    
    async def _switch_to_image_fallback_prompt(self, query: str, image_data: Dict) -> bool:
        """
        åˆ‡æ›åˆ°åŒ…å«åœ–ç‰‡çš„ Fallback æç¤ºè©
        """
        try:
            # æ ¼å¼åŒ–åŒ…å«åœ–ç‰‡çš„ Fallback æç¤ºè©
            image_fallback_prompt = self.image_fallback_prompt_template.format(
                query=query,
                image_format=image_data.get('format', 'jpeg'),
                image_size=image_data.get('size', 0)
            )
            
            # åˆ‡æ› VLM åˆ°åœ–ç‰‡ Fallback æ¨¡å¼
            success = await self._update_vlm_prompt(image_fallback_prompt)
            
            if success:
                self.current_state = PromptState.IMAGE_FALLBACK
                self._record_operation("switch_to_image_fallback", True, 
                                     f"Switched to image fallback prompt for query: {query[:30]}...")
                logger.debug("Successfully switched to image fallback prompt")
                return True
            else:
                raise PromptSwitchError("Failed to update VLM prompt for image fallback")
                
        except Exception as e:
            self._record_operation("switch_to_image_fallback", False, str(e))
            logger.error(f"Failed to switch to image fallback prompt: {e}")
            raise PromptSwitchError(f"Failed to switch to image fallback prompt: {e}")
    
    async def _execute_vlm_query_with_image(self, query: str, image_data: Dict) -> str:
        """
        åŸ·è¡ŒåŒ…å«åœ–ç‰‡çš„ VLM æŸ¥è©¢
        """
        try:
            # å‰µå»ºåŒ…å«åœ–ç‰‡çš„è«‹æ±‚è¼‰è·
            request_payload = {
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": query
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/{image_data['format']};base64,{image_data['image_data']}"
                                }
                            }
                        ]
                    }
                ],
                "max_tokens": 500,
                "temperature": 0.7
            }
            
            # ç™¼é€è«‹æ±‚åˆ° VLM æœå‹™
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                response = await client.post(
                    f"{self.model_server_url}/v1/chat/completions",
                    json=request_payload
                )
                
                if response.status_code != 200:
                    raise Exception(f"VLM service error: {response.status_code}")
                
                response_data = response.json()
                
                # æå–å›æ‡‰æ–‡å­—
                if 'choices' in response_data and len(response_data['choices']) > 0:
                    content = response_data['choices'][0]['message']['content']
                    
                    # è™•ç†ä¸åŒå›æ‡‰æ ¼å¼
                    if isinstance(content, str):
                        return content.strip()
                    elif isinstance(content, list):
                        # å¾åˆ—è¡¨æ ¼å¼æå–æ–‡å­—
                        text_parts = []
                        for item in content:
                            if isinstance(item, dict) and item.get('type') == 'text':
                                text_parts.append(item.get('text', ''))
                            elif isinstance(item, str):
                                text_parts.append(item)
                        return ' '.join(text_parts).strip()
                    else:
                        return str(content).strip()
                else:
                    raise Exception("Invalid VLM response format")
                    
        except Exception as e:
            logger.error(f"VLM query with image execution failed: {e}")
            raise Exception(f"VLM query with image failed: {e}")
```

## ğŸ“ å¯¦ç¾è¨ˆåŠƒ

### éšæ®µ 1ï¼šæ ¸å¿ƒåŠŸèƒ½å¯¦ç¾ (3-4 å¤©)

#### Task 1.1: åœ–ç‰‡ç²å–ç®¡ç†å™¨å¯¦ç¾
- **æ–‡ä»¶**: `src/vlm_fallback/image_capture_manager.py`
- **å­ä»»å‹™**:
  - [ ] å¯¦ç¾ `ImageCaptureManager` é¡
  - [ ] å¯¦ç¾ç›¸æ©Ÿåœ–ç‰‡ç²å–åŠŸèƒ½
  - [ ] å¯¦ç¾ç‹€æ…‹è¿½è¹¤å™¨åœ–ç‰‡ç²å–åŠŸèƒ½
  - [ ] å¯¦ç¾åœ–ç‰‡é è™•ç†å’Œç·©å­˜
  - [ ] æ·»åŠ éŒ¯èª¤è™•ç†å’Œé™ç´šæ©Ÿåˆ¶
- **ä¼°è¨ˆæ™‚é–“**: 6 å°æ™‚
- **ä¾è³´**: ç¾æœ‰çš„åœ–ç‰‡è™•ç†ç³»çµ±

#### Task 1.2: å¢å¼·å‹ VLM Fallback è™•ç†å™¨
- **æ–‡ä»¶**: `src/vlm_fallback/enhanced_fallback_processor.py`
- **å­ä»»å‹™**:
  - [ ] æ“´å±• `VLMFallbackProcessor` é¡
  - [ ] å¯¦ç¾ `process_query_with_image_fallback()` æ–¹æ³•
  - [ ] å¯¦ç¾ `_execute_enhanced_vlm_fallback()` æ–¹æ³•
  - [ ] é›†æˆåœ–ç‰‡ç²å–ç®¡ç†å™¨
  - [ ] ä¿æŒå‘å¾Œå…¼å®¹æ€§
- **ä¼°è¨ˆæ™‚é–“**: 4 å°æ™‚
- **ä¾è³´**: Task 1.1

#### Task 1.3: å¢å¼·å‹æç¤ºè©ç®¡ç†å™¨
- **æ–‡ä»¶**: `src/vlm_fallback/enhanced_prompt_manager.py`
- **å­ä»»å‹™**:
  - [ ] æ“´å±• `PromptManager` é¡
  - [ ] å¯¦ç¾ `execute_fallback_with_image()` æ–¹æ³•
  - [ ] å¯¦ç¾ `_switch_to_image_fallback_prompt()` æ–¹æ³•
  - [ ] å¯¦ç¾ `_execute_vlm_query_with_image()` æ–¹æ³•
  - [ ] æ·»åŠ åœ–ç‰‡ Fallback æç¤ºè©æ¨¡æ¿
- **ä¼°è¨ˆæ™‚é–“**: 5 å°æ™‚
- **ä¾è³´**: Task 1.1

### éšæ®µ 2ï¼šç³»çµ±é›†æˆ (2-3 å¤©)

#### Task 2.1: ä¿®æ”¹ QueryProcessor
- **æ–‡ä»¶**: `src/state_tracker/query_processor.py`
- **å­ä»»å‹™**:
  - [ ] å°å…¥å¢å¼·å‹ VLM Fallback è™•ç†å™¨
  - [ ] ä¿®æ”¹ `process_query()` æ–¹æ³•æ”¯æ´åœ–ç‰‡ Fallback
  - [ ] æ·»åŠ åœ–ç‰‡ Fallback é…ç½®é¸é …
  - [ ] ä¿æŒç¾æœ‰åŠŸèƒ½ä¸è®Š
- **ä¼°è¨ˆæ™‚é–“**: 3 å°æ™‚
- **ä¾è³´**: Task 1.2

#### Task 2.2: é…ç½®ç®¡ç†å¢å¼·
- **æ–‡ä»¶**: `src/vlm_fallback/config.py`
- **å­ä»»å‹™**:
  - [ ] æ·»åŠ åœ–ç‰‡ Fallback é…ç½®é¸é …
  - [ ] æ·»åŠ åœ–ç‰‡ç²å–é…ç½®
  - [ ] æ·»åŠ åœ–ç‰‡è™•ç†é…ç½®
  - [ ] å¯¦ç¾é…ç½®é©—è­‰
- **ä¼°è¨ˆæ™‚é–“**: 2 å°æ™‚
- **ä¾è³´**: Task 1.1

### éšæ®µ 3ï¼šæ¸¬è©¦é©—è­‰ (2-3 å¤©)

#### Task 3.1: å–®å…ƒæ¸¬è©¦
- **æ–‡ä»¶**: `tests/vlm_fallback/test_image_enhancement.py`
- **å­ä»»å‹™**:
  - [ ] æ¸¬è©¦åœ–ç‰‡ç²å–ç®¡ç†å™¨
  - [ ] æ¸¬è©¦å¢å¼·å‹ Fallback è™•ç†å™¨
  - [ ] æ¸¬è©¦å¢å¼·å‹æç¤ºè©ç®¡ç†å™¨
  - [ ] æ¸¬è©¦éŒ¯èª¤è™•ç†å’Œé™ç´š
- **ä¼°è¨ˆæ™‚é–“**: 4 å°æ™‚

#### Task 3.2: é›†æˆæ¸¬è©¦
- **æ–‡ä»¶**: `tests/vlm_fallback/test_image_integration.py`
- **å­ä»»å‹™**:
  - [ ] æ¸¬è©¦å®Œæ•´çš„åœ–ç‰‡ Fallback æµç¨‹
  - [ ] æ¸¬è©¦èˆ‡ç¾æœ‰ç³»çµ±çš„å…¼å®¹æ€§
  - [ ] æ¸¬è©¦æ€§èƒ½å½±éŸ¿
  - [ ] æ¸¬è©¦ä¸¦ç™¼è™•ç†
- **ä¼°è¨ˆæ™‚é–“**: 5 å°æ™‚

#### Task 3.3: ç«¯åˆ°ç«¯æ¸¬è©¦
- **æ–‡ä»¶**: `tests/e2e/test_image_fallback_e2e.py`
- **å­ä»»å‹™**:
  - [ ] æ¸¬è©¦çœŸå¯¦å ´æ™¯çš„åœ–ç‰‡ Fallback
  - [ ] æ¸¬è©¦ç”¨æˆ¶é«”é©—
  - [ ] æ¸¬è©¦éŒ¯èª¤æ¢å¾©
  - [ ] æ¸¬è©¦æ€§èƒ½åŸºæº–
- **ä¼°è¨ˆæ™‚é–“**: 4 å°æ™‚

## ğŸ”§ é…ç½®è¦æ ¼

### é…ç½®æ–‡ä»¶å¢å¼·
```json
{
  "vlm_fallback": {
    "enable_image_fallback": true,
    "image_capture": {
      "enable_camera_capture": true,
      "enable_state_tracker_capture": true,
      "enable_image_cache": true,
      "cache_duration_seconds": 300,
      "max_image_size_bytes": 1048576
    },
    "image_processing": {
      "default_model": "smolvlm",
      "quality": 85,
      "max_size": 1024,
      "format": "jpeg"
    },
    "fallback_prompts": {
      "image_fallback_template": "You are a helpful AI assistant with visual capabilities. Please analyze the provided image and answer the user's question.\n\nUser Question: {query}\n\nImage Format: {image_format}\nImage Size: {image_size} bytes\n\nPlease provide a clear, accurate, and helpful response based on both the image content and the user's question. Focus on:\n- Visual analysis of the image\n- Answering the specific question\n- Providing practical guidance when appropriate\n- Being concise but complete\n- Using a friendly and supportive tone\n\nAnswer:"
    }
  }
}
```

## ğŸ“Š æ€§èƒ½è€ƒé‡

### æ€§èƒ½ç›®æ¨™
- **åœ–ç‰‡ç²å–æ™‚é–“**: < 500ms
- **åœ–ç‰‡é è™•ç†æ™‚é–“**: < 1s
- **VLM éŸ¿æ‡‰æ™‚é–“**: < 15s (åŒ…å«åœ–ç‰‡è™•ç†)
- **ç¸½éŸ¿æ‡‰æ™‚é–“**: < 20s
- **è¨˜æ†¶é«”ä½¿ç”¨**: åœ–ç‰‡ç·©å­˜ < 50MB

### å„ªåŒ–ç­–ç•¥
1. **åœ–ç‰‡ç·©å­˜**: é¿å…é‡è¤‡ç²å–ç›¸åŒåœ–ç‰‡
2. **ç•°æ­¥è™•ç†**: ä¸¦è¡Œè™•ç†åœ–ç‰‡ç²å–å’Œé è™•ç†
3. **é™ç´šæ©Ÿåˆ¶**: åœ–ç‰‡ç²å–å¤±æ•—æ™‚å›é€€åˆ°ç´”æ–‡å­—
4. **è³‡æºç®¡ç†**: åŠæ™‚æ¸…ç†åœ–ç‰‡ç·©å­˜

## ğŸ§ª æ¸¬è©¦ç­–ç•¥

### æ¸¬è©¦å ´æ™¯
1. **æ­£å¸¸å ´æ™¯**: åœ–ç‰‡ç²å–æˆåŠŸï¼ŒVLM æ­£å¸¸å›æ‡‰
2. **åœ–ç‰‡ç²å–å¤±æ•—**: ç›¸æ©Ÿä¸å¯ç”¨ï¼Œå›é€€åˆ°ç´”æ–‡å­—
3. **VLM æœå‹™ç•°å¸¸**: åœ–ç‰‡æ­£å¸¸ä½† VLM å¤±æ•—
4. **åœ–ç‰‡è™•ç†å¤±æ•—**: åœ–ç‰‡æ ¼å¼ä¸æ”¯æ´
5. **ä¸¦ç™¼æ¸¬è©¦**: å¤šç”¨æˆ¶åŒæ™‚ä½¿ç”¨åœ–ç‰‡ Fallback

### æ¸¬è©¦æ•¸æ“š
- **æ¸¬è©¦åœ–ç‰‡**: å„ç¨®æ ¼å¼å’Œå¤§å°
- **æ¸¬è©¦æŸ¥è©¢**: è¦–è¦ºç›¸é—œå’Œéè¦–è¦ºç›¸é—œ
- **æ€§èƒ½åŸºæº–**: éŸ¿æ‡‰æ™‚é–“å’Œè³‡æºä½¿ç”¨

## ğŸš€ éƒ¨ç½²è¨ˆåŠƒ

### éƒ¨ç½²éšæ®µ
1. **é–‹ç™¼ç’°å¢ƒ**: åŠŸèƒ½é–‹ç™¼å’Œå–®å…ƒæ¸¬è©¦
2. **æ¸¬è©¦ç’°å¢ƒ**: é›†æˆæ¸¬è©¦å’Œæ€§èƒ½æ¸¬è©¦
3. **é ç”Ÿç”¢ç’°å¢ƒ**: ç«¯åˆ°ç«¯æ¸¬è©¦å’Œç”¨æˆ¶é©—æ”¶
4. **ç”Ÿç”¢ç’°å¢ƒ**: é€æ­¥éƒ¨ç½²å’Œç›£æ§

### ç›£æ§æŒ‡æ¨™
- **åœ–ç‰‡ Fallback ä½¿ç”¨ç‡**
- **åœ–ç‰‡ç²å–æˆåŠŸç‡**
- **VLM éŸ¿æ‡‰æ™‚é–“**
- **éŒ¯èª¤ç‡å’Œé™ç´šç‡**
- **ç”¨æˆ¶æ»¿æ„åº¦**

## ğŸ“š æ–‡æª”æ›´æ–°

### éœ€è¦æ›´æ–°çš„æ–‡æª”
1. **VLM Fallback ç”¨æˆ¶æŒ‡å—**: æ·»åŠ åœ–ç‰‡åŠŸèƒ½èªªæ˜
2. **é–‹ç™¼è€…æ–‡æª”**: æ·»åŠ åœ–ç‰‡ Fallback API æ–‡æª”
3. **é…ç½®æ–‡æª”**: æ·»åŠ åœ–ç‰‡ç›¸é—œé…ç½®èªªæ˜
4. **æ•…éšœæ’é™¤æŒ‡å—**: æ·»åŠ åœ–ç‰‡ç›¸é—œå•é¡Œè§£æ±ºæ–¹æ¡ˆ

## ğŸ”„ å‘å¾Œå…¼å®¹æ€§

### å…¼å®¹æ€§ä¿è­‰
1. **ç¾æœ‰åŠŸèƒ½ä¸è®Š**: ç´”æ–‡å­— Fallback åŠŸèƒ½ä¿æŒä¸è®Š
2. **é…ç½®å‘å¾Œå…¼å®¹**: èˆŠé…ç½®æª”æ¡ˆä»ç„¶æœ‰æ•ˆ
3. **API å‘å¾Œå…¼å®¹**: ç¾æœ‰ API æ¥å£ä¸è®Š
4. **ç”¨æˆ¶é«”é©—ä¸€è‡´**: ç”¨æˆ¶ç„¡æ³•æ„ŸçŸ¥å…§éƒ¨è®ŠåŒ–

### é·ç§»ç­–ç•¥
1. **æ¼¸é€²å¼å•Ÿç”¨**: å¯é…ç½®å•Ÿç”¨åœ–ç‰‡ Fallback
2. **é™ç´šæ©Ÿåˆ¶**: åœ–ç‰‡åŠŸèƒ½å¤±æ•—æ™‚è‡ªå‹•é™ç´š
3. **ç›£æ§å‘Šè­¦**: åŠæ™‚ç™¼ç¾å’Œè™•ç†å•é¡Œ
4. **å›æ»¾è¨ˆåŠƒ**: å•é¡Œæ™‚å¿«é€Ÿå›æ»¾åˆ°ç´”æ–‡å­—æ¨¡å¼

---

**ç¸½çµ**: é€™å€‹å¢å¼·åŠŸèƒ½å°‡é¡¯è‘—æå‡ VLM Fallback ç³»çµ±çš„èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤ æä¾›åŸºæ–¼è¦–è¦ºä¸Šä¸‹æ–‡çš„æ™ºèƒ½å›æ‡‰ï¼ŒåŒæ™‚ä¿æŒç³»çµ±çš„ç©©å®šæ€§å’Œå‘å¾Œå…¼å®¹æ€§ã€‚ 